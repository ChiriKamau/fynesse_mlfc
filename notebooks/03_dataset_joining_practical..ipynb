{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOQTo7elNfi9"
      },
      "source": [
        "# Practical 3: Dataset Joining and Access-Assess-Address Framework\n",
        "\n",
        "### Radzim Sendyka\n",
        "\n",
        "### [Neil D. Lawrence](http://inverseprobability.com), University of\n",
        "\n",
        "Cambridge\n",
        "\n",
        "### 2025-09-08"
      ],
      "id": "ZOQTo7elNfi9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MYci3uuNfjM"
      },
      "source": [
        "**Abstract**: In this lab session we will explore dataset joining\n",
        "techniques, implement the Access-Assess-Address framework in practice,\n",
        "work with the DSAIL Porini camera trap data, and build predictive models\n",
        "for animal sightings."
      ],
      "id": "5MYci3uuNfjM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17yUMINPNfjR"
      },
      "source": [
        "$$\n",
        "$$"
      ],
      "id": "17yUMINPNfjR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvvJwKcoNfjV"
      },
      "source": [
        "<!-- Do not edit this file locally. -->\n",
        "<!-- Do not edit this file locally. -->\n",
        "<!---->\n",
        "<!-- Do not edit this file locally. -->\n",
        "<!-- Do not edit this file locally. -->\n",
        "<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->\n",
        "<!--\n",
        "\n",
        "-->"
      ],
      "id": "bvvJwKcoNfjV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBZPKWV2NfjZ"
      },
      "source": [
        "## Code Reuse with Fynesse\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_data-science/includes/osm-code-reuse-fynesse.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/osm-code-reuse-fynesse.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "{We will be reusing some of the functions we created in the first\n",
        "practical. This demonstrates one of the key principles of data science:\n",
        "building reusable code libraries that can be applied across multiple\n",
        "projects."
      ],
      "id": "zBZPKWV2NfjZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gae4x2hNfjd"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install osmnx"
      ],
      "id": "8gae4x2hNfjd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9GoItxKNfjk"
      },
      "source": [
        "### Exercise 1\n",
        "\n",
        "Install your Fyness library, and run code to show its available."
      ],
      "id": "F9GoItxKNfjk"
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete repo\n",
        "!rm -rf fynesse_mlfc"
      ],
      "metadata": {
        "id": "X75jLIB5N6pn"
      },
      "id": "X75jLIB5N6pn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Xk5qSqhNfjq"
      },
      "outputs": [],
      "source": [
        "# Write your answer to Exercise 1 here\n",
        "\n",
        "\n",
        "!git clone https://github.com/ChiriKamau/fynesse_mlfc.git\n",
        "%cd fynesse_mlfc\n",
        "sys.path.insert(0, '/content/fynesse_mlfc')\n",
        "sys.path.insert(0, '/content/fynesse_mlfc/fynesse')\n",
        "print(\"imemaliza\")\n",
        "\n"
      ],
      "id": "4Xk5qSqhNfjq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCr45OA-Nfju"
      },
      "outputs": [],
      "source": [
        "import fynesse\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/fynesse_mlfc/fynesse')\n",
        "\n",
        "\n",
        "\n",
        "# ACCSS:\n",
        "print(\" Setting up data access\")\n",
        "nyeri_data = fynesse.access.DataAccess(\"Nyeri, Kenya\", -0.4371, 36.9580)\n",
        "\n",
        "# Get all the data\n",
        "nyeri_data.access_all_data()\n",
        "print(f\"Data accessed for {nyeri_data.place_name}\")\n",
        "\n",
        "# ASSESS: Analyze the data\n",
        "assessor = fynesse.assess.DataAssessment(nyeri_data)\n",
        "poi_analysis = assessor.assess_poi_distribution()\n",
        "print(\"POI analysis complete\")\n",
        "\n",
        "# ADDRESS: Create visualization\n",
        "addresser = DataSolution(nyeri_data)\n",
        "addresser.address_visualization(figsize=(10,8))\n"
      ],
      "id": "SCr45OA-Nfju"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQ5igKkcNfjx"
      },
      "source": [
        "## DSAIL-Porini Dataset\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_datasets/includes/dsail-porini-data.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_datasets/includes/dsail-porini-data.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "Head over to https://data.mendeley.com/datasets/6mhrhn7rxc/6 to explore\n",
        "the DSAIL-Porini dataset. This dataset contains camera trap images and\n",
        "annotations from Kenya, providing rich information about wildlife\n",
        "patterns and behavior.\n",
        "\n",
        "Locate the `camera_trap_dataset_annotation.xlsx` file and make it\n",
        "available in this notebook."
      ],
      "id": "PQ5igKkcNfjx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwz7QrOwNfj0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import pandas as pd"
      ],
      "id": "dwz7QrOwNfj0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqM97xlcNfj2"
      },
      "outputs": [],
      "source": [
        "def download_if_not_exists(url, filepath):\n",
        "    \"\"\"Download file if it doesn't exist locally\"\"\"\n",
        "    if os.path.exists(filepath):\n",
        "        print(f\"File already exists: {filepath}\")\n",
        "    else:\n",
        "        print(f\"Downloading: {url}\")\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()\n",
        "        with open(filepath, \"wb\") as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "        print(f\"Downloaded to: {filepath}\")\n",
        "    return filepath"
      ],
      "id": "fqM97xlcNfj2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRhNZa8XNfj6"
      },
      "outputs": [],
      "source": [
        "# Download the DSAIL-Porini dataset\n",
        "porini_file = download_if_not_exists(\n",
        "    'https://data.mendeley.com/public-files/datasets/6mhrhn7rxc/files/641e83c9-16a3-485c-b247-b5701f8a5540/file_downloaded',\n",
        "    'camera_trap_dataset_annotation.xlsx'\n",
        ")"
      ],
      "id": "PRhNZa8XNfj6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSbIHHdRNfj9"
      },
      "outputs": [],
      "source": [
        "porini_df = pd.read_excel(porini_file)\n",
        "porini_df.head()"
      ],
      "id": "BSbIHHdRNfj9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oini_DPNNfj_"
      },
      "source": [
        "## Joining Datasets\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_data-science/includes/dsail-porini-data-joining.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/dsail-porini-data-joining.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
      ],
      "id": "oini_DPNNfj_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqDnGBicNfkB"
      },
      "source": [
        "### Exercise 2\n",
        "\n",
        "Geospatial data is particularly useful because it is the most common\n",
        "index in the world, over which so many datasets can be joined. Find the\n",
        "coordinate information in the dataset, and plot it on top of an OSM map.\n",
        "\n",
        "You may want to deduplicate the coordinates before you plot!"
      ],
      "id": "kqDnGBicNfkB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEgTHn75NfkC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Load the dataset\n",
        "df = pd.read_excel('camera_trap_dataset_annotation.xlsx')\n",
        "\n",
        "# Find coordinate columns automlat_col = lon_col = None\n",
        "for col in df.columns:\n",
        "    col_lower = col.lower()\n",
        "    if 'latitude' in col_lower:\n",
        "        lat_col = col\n",
        "    elif 'longitude' in col_lower:\n",
        "        lon_col = col\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "\n",
        "# Extract coordinates and remove missing values\n",
        "coords_df = df[[lat_col, lon_col]].dropna()\n",
        "\n",
        "# Deduplicate coordinates\n",
        "unique_coords = coords_df.drop_duplicates()\n",
        "print(f\"Unique locations: {len(unique_coords)} (from {len(coords_df)} total observations)\")\n",
        "\n",
        "# Create map centered on data\n",
        "center_lat = unique_coords[lat_col].mean()\n",
        "center_lon = unique_coords[lon_col].mean()\n",
        "\n",
        "m = folium.Map(location=[center_lat, center_lon], zoom_start=14, tiles='OpenStreetMap')\n",
        "\n",
        "# Add markers for each unique coordinate\n",
        "for _, row in unique_coords.iterrows():\n",
        "    folium.CircleMarker(\n",
        "        location=[row[lat_col], row[lon_col]],\n",
        "        radius=8,\n",
        "        popup=f\"Lat: {row[lat_col]:.6f}<br>Lon: {row[lon_col]:.6f}\",\n",
        "        color='red',\n",
        "        fillColor='red',\n",
        "        fillOpacity=0.6\n",
        "    ).add_to(m)\n",
        "\n",
        "# Fit map to show all points\n",
        "if len(unique_coords) > 1:\n",
        "    sw = [unique_coords[lat_col].min(), unique_coords[lon_col].min()]\n",
        "    ne = [unique_coords[lat_col].max(), unique_coords[lon_col].max()]\n",
        "    m.fit_bounds([sw, ne])\n",
        "\n",
        "# Display map\n",
        "m\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "cEgTHn75NfkC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PtC82g5NfkE"
      },
      "source": [
        "<!-- Dsail Porini Address -->"
      ],
      "id": "6PtC82g5NfkE"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1uZRpSqNfkG"
      },
      "source": [
        "## Sighting Predictions\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_data-science/includes/dsail-porini-data-preprocessing.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/dsail-porini-data-preprocessing.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "We will use the dataset to create a simple prediction model for the\n",
        "likelihood of animal sightings.\n",
        "\n",
        "Let’s follow a minimal example of the Access-Assess-Address framework!\n",
        "\n",
        "Reminder about Neil’s article on the framework\n",
        "[here](https://inverseprobability.com/talks/notes/access-assess-address-a-pipeline-for-automated-data-science.html)."
      ],
      "id": "m1uZRpSqNfkG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp-TElYUNfkL"
      },
      "source": [
        "### Access\n",
        "\n",
        "Access is already done, partly years ago by the DSAIL team, and two\n",
        "cells above by us. Example tasks within access would be:\n",
        "\n",
        "-   Setting up the cameras in the woods (done)\n",
        "-   Collecting the pictures (done)\n",
        "-   Labeling the dataset (done)\n",
        "-   Making the excel file online accessible (done)\n",
        "-   Downloading the file (done just now)}"
      ],
      "id": "Kp-TElYUNfkL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_HDWCeiNfkN"
      },
      "outputs": [],
      "source": [
        "porini_df.head()"
      ],
      "id": "t_HDWCeiNfkN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhyAFV92NfkO"
      },
      "source": [
        "### Assess\n",
        "\n",
        "Have a look at the dataset for any issues that could stop us from being\n",
        "able to cleanly analyse it.\n",
        "\n",
        "Some issues:\n",
        "\n",
        "-   Timestamps not readilly available. Hidden in image filenames.\n",
        "-   No timestamps available for one of the cameras.\n",
        "-   No Camera ID, but can be deduced from coordinates.\n",
        "\n",
        "Decide how it would be best to address these and potentially other\n",
        "issues with the data.\n",
        "\n",
        "We would like an output dataframe that has a column for counts each\n",
        "animal was spotted by each camera, and rows for each day in the\n",
        "available range. You might want to use this opportunity to practice\n",
        "[Pandas\n",
        "MultiIndex](https://pandas.pydata.org/docs/user_guide/advanced.html)."
      ],
      "id": "EhyAFV92NfkO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amB3YsbgNfkQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ],
      "id": "amB3YsbgNfkQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ5iAEkBNfkR"
      },
      "outputs": [],
      "source": [
        "# Copy original\n",
        "df = porini_df.copy()\n",
        "\n",
        "# Normalize species and parse counts\n",
        "df[\"Species\"] = df[\"Species\"].astype(str).str.strip()\n",
        "\n",
        "# Extract timestamp from filename\n",
        "pat = re.compile(r\"(\\d{4})-(\\d{2})-(\\d{2})-(\\d{2})-(\\d{2})-(\\d{2})\")\n",
        "def parse_ts(name):\n",
        "    m = pat.search(str(name))\n",
        "    if not m:\n",
        "        return pd.NaT\n",
        "    y, M, d, h, m_, s = map(int, m.groups())\n",
        "    return pd.Timestamp(y, M, d, h, m_, s)\n",
        "\n",
        "df[\"timestamp\"] = df[\"Filename\"].map(parse_ts)\n",
        "df[\"date\"] = df[\"timestamp\"].dt.date\n",
        "\n",
        "# Camera ID from rounded lat/lon\n",
        "df[\"Latitude\"] = df[\"Latitude\"].round(4)\n",
        "df[\"Longitude\"] = df[\"Longitude\"].round(4)\n",
        "coord_key = df[\"Latitude\"].astype(str) + \",\" + df[\"Longitude\"].astype(str)\n",
        "codes, _ = pd.factorize(coord_key)\n",
        "df[\"camera_id\"] = pd.Series(codes).map(lambda i: f\"C{int(i)+1:03d}\")\n",
        "\n",
        "# Extract camera coordinates dictionary (rounded)\n",
        "camera_coords = (\n",
        "    df.drop_duplicates(subset=\"camera_id\")[[\"camera_id\", \"Latitude\", \"Longitude\"]]\n",
        "      .set_index(\"camera_id\")\n",
        "      .sort_index()\n",
        "      .apply(tuple, axis=1)\n",
        "      .to_dict()\n",
        ")\n",
        "\n",
        "# Group and count: number of pictures per species per camera per day\n",
        "daily = (\n",
        "    df.dropna(subset=[\"date\"])\n",
        "      .groupby([\"date\", \"camera_id\", \"Species\"])\n",
        "      .size()\n",
        "      .reset_index(name=\"photo_count\")\n",
        "      .pivot_table(index=\"date\", columns=[\"camera_id\", \"Species\"], values=\"photo_count\", aggfunc=\"sum\")\n",
        "      .fillna(0)\n",
        "      .astype(int)\n",
        "      .sort_index()\n",
        ")\n",
        "\n",
        "# Fill missing dates\n",
        "if not daily.empty:\n",
        "    full_idx = pd.date_range(start=daily.index.min(), end=daily.index.max(), freq=\"D\").date\n",
        "    daily = daily.reindex(full_idx).fillna(0).astype(int)\n",
        "    daily.index.name = \"date\"\n",
        "\n",
        "print(camera_coords)\n",
        "daily.tail()"
      ],
      "id": "OJ5iAEkBNfkR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEVVt71ANfkT"
      },
      "source": [
        "Huh, looks like we have some more issues.\n",
        "\n",
        "-   “Impala, Monkey” is not a species - should be counted towards two!\n",
        "-   “Can’t Tell” shouldn’t be a species at all.\n",
        "-   Some columns don’t exist (eg. `C011` has no `ZEBRA`). Let’s just\n",
        "    fill them with zeros.\n",
        "\n",
        "Additionally, there probably weren’t `1577` impalas spotted on Christmas\n",
        "Eve 2021. This is a result of burst shots repetitively capturing the\n",
        "same animal. For now, let’s just treat the data as binary, whether at\n",
        "least one photo was taken on that day."
      ],
      "id": "aEVVt71ANfkT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lJ0HAKZNfkV"
      },
      "source": [
        "### Exercise 3\n",
        "\n",
        "Use the cell below to implement the changes discussed above, and\n",
        "potentially additional issues."
      ],
      "id": "1lJ0HAKZNfkV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBgCb0PmNfkW"
      },
      "outputs": [],
      "source": [
        "# Write your answer to Exercise 3 here\n",
        "\n",
        "\n",
        "daily_bin = daily.copy()\n",
        "# Step 1: Flatten the multi-index and reshape the dataframe\n",
        "\n",
        "daily_bin.columns = pd.MultiIndex.from_tuples(daily_bin.columns)\n",
        "\n",
        "# Step 2: Create a new clean dataframe\n",
        "binary_rows = []\n",
        "\n",
        "for (cam, species_str), series in daily_bin.items():\n",
        "    # Split species (e.g. \"IMPALA, MONKEY\") into a list of individual species\n",
        "    # ignore the \"CAN'T TELL\" species\n",
        "    species_list = [] #TODO\n",
        "\n",
        "    for species in species_list:\n",
        "\n",
        "      col = pd.Series(series, index=series.index)\n",
        "      # Convert every value to 1 if any sightings, otherwise 0\n",
        "      col_bin =\n",
        "      binary_rows.append((cam, species, col_bin))\n",
        "\n",
        "# Step 3: Rebuild dataframe as binary_df\n",
        "\n",
        "binary_df = pd.DataFrame({\n",
        "    (cam, species): values\n",
        "    for cam, species, values in binary_rows\n",
        "}, index=daily_bin.index)\n",
        "\n",
        "# Step 4: Create MultiIndex and\n",
        "binary_df.columns = pd.MultiIndex.from_tuples(binary_df.columns)\n",
        "binary_df = binary_df.sort_index(axis=1, level=[0, 1])\n",
        "\n",
        "# Step 5: Ensure all possible (camera, species) pairs exist\n",
        "\n",
        "# Get all unique cameras and species used across all rows and store as a list\n",
        "all_cameras = [] #TODO\n",
        "all_species = [] #TODO\n",
        "\n",
        "# Build full column MultiIndex\n",
        "full_columns = pd.MultiIndex.from_product([all_cameras, all_species], names=[\"camera_id\", \"Species\"])\n",
        "\n",
        "# Reindex to include all possible combinations, fill missing with 0\n",
        "binary_df = binary_df.reindex(columns=full_columns, fill_value=0)\n",
        "\n",
        "binary_df.tail()\n",
        "\n"
      ],
      "id": "YBgCb0PmNfkW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8IBiiPjNfkY"
      },
      "source": [
        "## Statistical Analysis of Sighting Patterns\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_data-science/includes/dsail-porini-probability-analysis.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/dsail-porini-probability-analysis.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
      ],
      "id": "Y8IBiiPjNfkY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyuqeMNYNfkc"
      },
      "source": [
        "### Exercise 4\n",
        "\n",
        "Now let’s create a simple prediction system for whether a specific\n",
        "`camera` captured a `species` on a given `date`. Let’s use the whole\n",
        "dataset, except for the prediction target date.\n",
        "\n",
        "Before we jump into addressing the question, let’s further assess the\n",
        "data. Calculate and plot average probabilities for dates, species, and\n",
        "cameras. You may want to implement some smoothing over dates, or group\n",
        "them into longer ranges."
      ],
      "id": "nyuqeMNYNfkc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQtXSFZWNfke"
      },
      "outputs": [],
      "source": [
        "# Write your answer to Exercise 4 here\n",
        "\n",
        "\n",
        "if not isinstance(df.index, (pd.DatetimeIndex, pd.PeriodIndex, pd.TimedeltaIndex)):\n",
        "        df = df.copy()\n",
        "        df.index = pd.to_datetime(df.index, errors=\"coerce\")\n",
        "df = df.sort_index()\n",
        "\n",
        "# raw daily mean across all (camera, species)\n",
        "avg_by_date_raw = df.mean(axis=1)\n",
        "\n",
        "\n",
        "# set and apply smooth frequency\n",
        "smooth_freq = \"ME\" # Monthly average, \"YE\" would be yearly\n",
        "avg_by_date_smooth = avg_by_date_raw.resample(smooth_freq).mean()\n",
        "\n",
        "# plot raw + smoothed\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.plot(avg_by_date_raw.index, avg_by_date_raw.values, alpha=0.4, label=\"Daily (raw)\")\n",
        "plt.plot(avg_by_date_smooth.index, avg_by_date_smooth.values, linewidth=2, label=f\"Smoothed (Monthly Average)\")\n",
        "plt.title(\"Average Sighting Probability Over Time\")\n",
        "plt.xlabel(\"Date\"); plt.ylabel(\"Probability\"); plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#Print these commands to help you understand what they do\n",
        "#print(binary_df.index)\n",
        "#print(binary_df.mean(axis=0))\n",
        "#print(binary_df.mean(axis=0).groupby(level=1).mean())\n",
        "\n",
        "#TODO Plot species and camera averages\n",
        "\n"
      ],
      "id": "GQtXSFZWNfke"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOeMGPAcNfkg"
      },
      "source": [
        "Extension: which of these relationships that you found are statistically\n",
        "significant?"
      ],
      "id": "uOeMGPAcNfkg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbAjHtS6Nfki"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ],
      "id": "rbAjHtS6Nfki"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G14ayDmfNfkk"
      },
      "source": [
        "## Address: Naive Bayesian Prediction Model\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/dsail-porini-naive-bayes.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/dsail-porini-naive-bayes.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "Using the data we collected in the Access stage and understood in\n",
        "Assess, we can now Address our question, and create a naive Bayesian\n",
        "classification model for predicting the probability of a camera sighting\n",
        "a species on a given day.\n",
        "\n",
        "$$\n",
        "P(1 \\mid c, s, d) = \\frac{P(1, c, s, d)}{P(c, s, d)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Using chain rule:} \\quad P(1, c, s, d) = P(1) \\cdot P(c, s, d \\mid 1)\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Using conditional independence:} \\quad P(c, s, d \\mid 1) = P(c \\mid 1) \\cdot P(s \\mid 1) \\cdot P(d \\mid 1)\n",
        "$$\n",
        "\n",
        "$$\n",
        "P(1 \\mid c, s, d) = \\frac{P(1) \\cdot P(c \\mid 1) \\cdot P(s \\mid 1) \\cdot P(d \\mid 1)}{P(c,s,d)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Using Bayes' rule:} \\quad  P(c \\mid 1) = \\frac{P(1 \\mid c) \\cdot P(c)}{P(1)} \\quad \\text{(and similarly for $s$ and $d$)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\Rightarrow P(1 \\mid c, s, d) = \\frac{P(1) \\cdot \\frac{P(1 \\mid c) \\cdot P(c)}{P(1)} \\cdot \\frac{P(1 \\mid s) \\cdot P(s)}{P(1)} \\cdot \\frac{P(1 \\mid d) \\cdot P(d)}{P(1)}}{P(c,s,d)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "= \\frac{P(1 \\mid c) \\cdot P(1 \\mid s) \\cdot P(1 \\mid d) \\cdot P(c) \\cdot P(s) \\cdot P(d)}{P(1)^2 \\cdot P(c,s,d)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\text{Assuming independence:}\n",
        "$$\n",
        "\n",
        "$$\n",
        "P(1 \\mid c,s,d)=\\frac{P(1 \\mid c) \\cdot P(1 \\mid s) \\cdot P(1 \\mid d)}{P(1)^2}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "&c = \\text{camera ID (e.g., C001)} \\\\\n",
        "&s = \\text{species (e.g., IMPALA)} \\\\\n",
        "&d = \\text{smoothed date (e.g., month, or Gaussian-filtered day)}\n",
        "\\end{align*}\n",
        "$$"
      ],
      "id": "G14ayDmfNfkk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHiO6BD5Nfkm"
      },
      "source": [
        "### Exercise 5\n",
        "\n",
        "Implement the model below."
      ],
      "id": "mHiO6BD5Nfkm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RP_Bd9zZNfkn"
      },
      "outputs": [],
      "source": [
        "# Write your answer to Exercise 5 here\n",
        "\n",
        "\n",
        "from typing import Union\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import date as DateType\n",
        "\n",
        "def bayes_sighting_probability(df, camera, species, date) -> float:\n",
        "    \"\"\"\n",
        "    Removes a specific observation and estimates the probability of sighting\n",
        "    a given species at a given camera on a specific date.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): DataFrame with MultiIndex columns (camera, species) and datetime.date index.\n",
        "        camera (str): Camera ID (e.g. 'C001').\n",
        "        species (str): Species name (e.g. 'IMPALA').\n",
        "        date (str or datetime.date or pd.Timestamp): Date of the observation.\n",
        "\n",
        "    Returns:\n",
        "        float: Estimated sighting probability - TODO.\n",
        "    \"\"\"\n",
        "    if isinstance(date, str) or isinstance(date, pd.Timestamp):\n",
        "        date = pd.to_datetime(date).date()\n",
        "\n",
        "    df_blind = df.copy()\n",
        "    df_blind.loc[date, (camera, species)] = None\n",
        "\n",
        "    #TODO\n",
        "\n",
        "    raise NotImplementedError(\"Prediction logic not implemented yet.\")\n",
        "\n",
        "\n"
      ],
      "id": "RP_Bd9zZNfkn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqBAl3A9Nfkp"
      },
      "source": [
        "Well done! We should now have a working Access-Assess-Address data\n",
        "science pipeline! Let’s see how it does."
      ],
      "id": "MqBAl3A9Nfkp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZqA_oPINfks"
      },
      "outputs": [],
      "source": [
        "#"
      ],
      "id": "OZqA_oPINfks"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVrTHNVeNfku"
      },
      "source": [
        "### Evaluation\n",
        "\n",
        "The data is extremely sparse, with less than 1% of values being `1`.\n",
        "This is a challenge, as checking naive accuracy would make always-zero a\n",
        "very very good predictor.\n",
        "\n",
        "Let’s evaluate our prediction system using `log-loss`\n",
        "i.e. `cross-entropy`:\n",
        "\n",
        "$$\n",
        "\\mathcal{L} = - \\frac{1}{N} \\sum_{i=1}^{N}\n",
        "\\Big[\n",
        "    y_i \\, \\log(\\hat{p}_i) + (1 - y_i) \\, \\log(1 - \\hat{p}_i)\n",
        "\\Big]\n",
        "$$"
      ],
      "id": "vVrTHNVeNfku"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuNL-OUPNfkv"
      },
      "source": [
        "### Exercise 6\n",
        "\n",
        "Implement the loss function below."
      ],
      "id": "JuNL-OUPNfkv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dxKoKJgNflR"
      },
      "outputs": [],
      "source": [
        "# Write your answer to Exercise 6 here\n",
        "\n",
        "\n",
        "def cross_entropy(y_true, y_pred):\n",
        "    #TODO\n",
        "    raise NotImplementedError(\"Cross entropy not implemented yet.\")\n",
        "\n",
        "def evaluate_prediction_system(df, your_function, max_samples=1000):\n",
        "    # Randomly sample up to 1000, if full evaluation taking too long\n",
        "    np.random.seed(42)\n",
        "    coords = [(date, camera, species) for date in df.index for (camera, species) in df.columns]\n",
        "    if len(coords) > max_samples:\n",
        "        coords = np.random.choice(len(coords), size=max_samples, replace=False)\n",
        "        coords = [coords[i] if isinstance(coords[i], tuple) else\n",
        "                  [(date, camera, species) for date in df.index for (camera, species) in df.columns][coords[i]]\n",
        "                  for i in range(len(coords))]\n",
        "    else:\n",
        "        coords = coords\n",
        "\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    for date, camera, species in coords:\n",
        "        value = df.loc[date, (camera, species)]\n",
        "        y_true.append(value)\n",
        "        prob = your_function(df, camera, species, date)\n",
        "        y_pred.append(prob)\n",
        "\n",
        "    return cross_entropy(y_true, y_pred)\n",
        "\n",
        "# Let's pass our function to be evaluated. This could take quite some time if your function is complex.\n",
        "evaluate_prediction_system(binary_df, bayes_sighting_probability)\n",
        "\n"
      ],
      "id": "5dxKoKJgNflR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SA3lVT6kNflU"
      },
      "source": [
        "For reference, predicting a constant probability (eg. 0.5%) gives a loss\n",
        "of around 0.026. This should be the benchmark number we want to improve\n",
        "on. If your model does better than that, well done!\n",
        "\n",
        "*Note: our approach included look-ahead bias - making predictions based\n",
        "on data that we would not have access to at the time. For real-life\n",
        "deployment, we would need to limit our training data to before\n",
        "individual test cases.*"
      ],
      "id": "SA3lVT6kNflU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzAnqU6WNflV"
      },
      "source": [
        "## Improving the Method: Correlated Variables\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/dsail-porini-correlation-analysis-improvements.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/dsail-porini-correlation-analysis-improvements.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "The model above was quite simplified, and it disregarded any\n",
        "correlations between the three variables. Since cameras are close to\n",
        "each other, maybe they are more likely to capture the same animals on\n",
        "the same day? Maybe some animals like or avoid some areas, or some other\n",
        "animals? If any of the above is true, we can’t really be using simple\n",
        "Bayes’ rule classification."
      ],
      "id": "AzAnqU6WNflV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhYAd3aJNflY"
      },
      "source": [
        "### Exercise 7\n",
        "\n",
        "Analyse the data again to find the strongest relationships which can be\n",
        "used to improve predictions. Plot correlation matrices and other helpful\n",
        "charts.\n",
        "\n",
        "Have a short read through the [DSAIL-Porini\n",
        "paper](https://www.sciencedirect.com/science/article/pii/S2352340922010666)\n",
        "for inspiration about other probability analyses that can be done here."
      ],
      "id": "EhYAd3aJNflY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxkFjjUDNflZ"
      },
      "outputs": [],
      "source": [
        "# Write your answer to Exercise 7 here\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "mxkFjjUDNflZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLGKJCzeNfla"
      },
      "source": [
        "Extension: Use what you found to improve your prediction model, and\n",
        "compare it against the previous one."
      ],
      "id": "bLGKJCzeNfla"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BykbpE-hNflc"
      },
      "outputs": [],
      "source": [
        "from typing import Union\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import date as DateType\n",
        "\n",
        "def improved_sighting_probability(df, camera, species, date) -> float:\n",
        "    \"\"\"\n",
        "    Removes a specific observation and estimates the probability of sighting\n",
        "    a given species at a given camera on a specific date.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): DataFrame with MultiIndex columns (camera, species) and datetime.date index.\n",
        "        camera (str): Camera ID (e.g. 'C001').\n",
        "        species (str): Species name (e.g. 'IMPALA').\n",
        "        date (str or datetime.date or pd.Timestamp): Date of the observation.\n",
        "\n",
        "    Returns:\n",
        "        float: Estimated sighting probability - TODO.\n",
        "    \"\"\"\n",
        "    if isinstance(date, str) or isinstance(date, pd.Timestamp):\n",
        "        date = pd.to_datetime(date).date()\n",
        "\n",
        "    df_blind = df.copy()\n",
        "    df_blind.loc[date, (camera, species)] = None\n",
        "\n",
        "    #TODO\n",
        "\n",
        "    raise NotImplementedError(\"Prediction logic not implemented yet.\")"
      ],
      "id": "BykbpE-hNflc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMR4WDjvNflf"
      },
      "source": [
        "## Extended Exercises\n",
        "\n",
        "We didn’t use all of the available data when we just classified days as\n",
        "“sighting” or “no sighting.” Extend your analysis to include all the\n",
        "information in the file, like numbers of sightings and numbers of\n",
        "animals in the photos.\n",
        "\n",
        "This will be quite challenging due to burst shots - assess the dataset\n",
        "and come up with a good definition of what a burst is, and a data\n",
        "structure that has the information you chose as important.\n",
        "\n",
        "Example burst data: - Camera, Date, Species - Time Start, Time End -\n",
        "Number of photos - Average/most animals in a photo\n",
        "\n",
        "*Particular challenge around deduplicating multi-species sightings.*"
      ],
      "id": "wMR4WDjvNflf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xareHeemNflh"
      },
      "source": [
        "### Exercise 8\n",
        "\n",
        "Use this additional data and repeat the analysis you did above. Aim to\n",
        "further improve predictions and write a new function like\n",
        "`burst_sighting_probability('C001', 'IMPALA', '2021-12-24')`."
      ],
      "id": "xareHeemNflh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbPrsP-CNflj"
      },
      "outputs": [],
      "source": [
        "# Write your answer to Exercise 8 here\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "bbPrsP-CNflj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBmulThxNflk"
      },
      "source": [
        "### Exercise 9\n",
        "\n",
        "Compare the results and note the improvement (or lack thereof) against\n",
        "the two previous prediction functions you created."
      ],
      "id": "nBmulThxNflk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAkePYYeNfll"
      },
      "outputs": [],
      "source": [
        "# Write your answer to Exercise 9 here\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "VAkePYYeNfll"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlNFb_QRNfln"
      },
      "source": [
        "### Exercise 10\n",
        "\n",
        "What other benefits does your new system provide? Can you modify it to\n",
        "provide more predictions, like the expected number of sightings, the\n",
        "number of animals?"
      ],
      "id": "zlNFb_QRNfln"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ff5PhSJNflo"
      },
      "outputs": [],
      "source": [
        "# Write your answer to Exercise 10 here\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "0ff5PhSJNflo"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJfOiar7Nflq"
      },
      "source": [
        "## Database Integration with SQLite\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_datasets/includes/dsail-porini-sqlite-database-creation.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_datasets/includes/dsail-porini-sqlite-database-creation.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "Throughout the course you will work with various datasets and data\n",
        "formats. An SQL database is one of the most common ways to store large\n",
        "amounts of data. We recognise that many of you may be familiar with this\n",
        "already, but let’s use this example to build a small toy database of\n",
        "animal sightings based on the excel file and the dataframes we created."
      ],
      "id": "xJfOiar7Nflq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMY9X-qUNflt"
      },
      "source": [
        "### Exercise 11\n",
        "\n",
        "-   Create a local database (eg. `sqlite3`).\n",
        "-   Add a table with animal sighting data.\n",
        "-   Add a table with camera coordinates data.\n",
        "-   Set indices on columns you might search by (eg. `CameraID`, `Date`).\n",
        "    Make sure the index types make sense!\n",
        "-   Look into multi column indices, and set one on `Latitude` and\n",
        "    `Longitude`.\n",
        "-   Demonstrate success with a couple SQL queries, eg. counting `IMPALA`\n",
        "    sightings within a `200m` square around `-0.3866, 36.9649`.\n",
        "\n",
        "Helpful links:\n",
        "\n",
        "[SQL Intro, Creating Tables, Indices,\n",
        "Joins](https://www.w3schools.com/sql/sql_intro.asp)\n",
        "\n",
        "[Multi-Column\n",
        "Indices](https://stackoverflow.com/questions/179085/multiple-indexes-vs-multi-column-indexes)\n",
        "\n",
        "Remember to include reusable code from this and previous exercises in\n",
        "your Fynesse library!"
      ],
      "id": "RMY9X-qUNflt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAhroJodNflv"
      },
      "outputs": [],
      "source": [
        "# Write your answer to Exercise 11 here\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "wAhroJodNflv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbGxTTMONflw"
      },
      "source": [
        "## Extended Analysis: Burst Detection\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/dsail-porini-burst-detection-analysis.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/dsail-porini-burst-detection-analysis.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "We didn’t use all of the available data when we just classified days as\n",
        "“sighting” or “no sighting.” Change your analysis to include the number\n",
        "of sightings and the number of animals in the photos.\n",
        "\n",
        "This will be quite challenging due to burst shots - assess the dataset\n",
        "and come up with a good definition of what a burst is, and a data\n",
        "structure that has the information you chose as important.\n",
        "\n",
        "Example burst data: - Camera, Date, Species - Time Start, Time End -\n",
        "Number of photos - Average/most animals in a photo\n",
        "\n",
        "Particular hardship around deduplicating multi-species sightings."
      ],
      "id": "LbGxTTMONflw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp3PF-6XNfly"
      },
      "source": [
        "### Exercise 12\n",
        "\n",
        "Use this additional data and repeat the analysis you did above. Further\n",
        "improve predictions and write a new function like\n",
        "`burst_sighting_probability('C001', 'IMPALA', '2021-12-24')`."
      ],
      "id": "tp3PF-6XNfly"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z-lYFAYcNfl0"
      },
      "outputs": [],
      "source": [
        "# Write your answer to Exercise 12 here\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "Z-lYFAYcNfl0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-7KNcaGNfl1"
      },
      "source": [
        "### Exercise 13\n",
        "\n",
        "Compare the results and note the improvement (or lack thereof) against\n",
        "the two previous prediction functions you created."
      ],
      "id": "W-7KNcaGNfl1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyA5LBHbNfl3"
      },
      "outputs": [],
      "source": [
        "# Write your answer to Exercise 13 here\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "hyA5LBHbNfl3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytiWWKxUNfl4"
      },
      "source": [
        "### Exercise 14\n",
        "\n",
        "What other benefits does your new system provide? Can you modify it to\n",
        "provide more predictions, like the expected number of sightings, the\n",
        "number of animals?"
      ],
      "id": "ytiWWKxUNfl4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlLpmTobNfl5"
      },
      "outputs": [],
      "source": [
        "# Write your answer to Exercise 14 here\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "qlLpmTobNfl5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YQH3apSNfl7"
      },
      "source": [
        "End of Practical 3\n",
        "\n",
        "     _______  __   __  _______  __    _  ___   _  _______  __\n",
        "    |       ||  | |  ||   _   ||  |  | ||   | | ||       ||  |\n",
        "    |_     _||  |_|  ||  |_|  ||   |_| ||   |_| ||  _____||  |\n",
        "      |   |  |       ||       ||       ||      _|| |_____ |  |\n",
        "      |   |  |       ||       ||  _    ||     |_ |_____  ||__|\n",
        "      |   |  |   _   ||   _   || | |   ||    _  | _____| | __\n",
        "      |___|  |__| |__||__| |__||_|  |__||___| |_||_______||__|\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "## References"
      ],
      "id": "-YQH3apSNfl7"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": []
    }
  }
}