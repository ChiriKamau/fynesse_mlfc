{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL2Bhn5aKZL9"
      },
      "source": [
        "# Practical 2: Data and Python\n",
        "\n",
        "### Radzim Sendyka\n",
        "\n",
        "### 2025-09-02"
      ],
      "id": "nL2Bhn5aKZL9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGV-vzdIKZMw"
      },
      "source": [
        "**Abstract**: In this lab session we will explore the use of SQL and\n",
        "pandas with a football data base."
      ],
      "id": "KGV-vzdIKZMw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qPxiNoJKZM5"
      },
      "source": [
        "$$\n",
        "$$"
      ],
      "id": "1qPxiNoJKZM5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbPe6sb5KZNJ"
      },
      "source": [
        "<!-- Do not edit this file locally. -->\n",
        "<!-- Do not edit this file locally. -->\n",
        "<!---->\n",
        "<!-- Do not edit this file locally. -->\n",
        "<!-- Do not edit this file locally. -->\n",
        "<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->\n",
        "<!--\n",
        "\n",
        "-->"
      ],
      "id": "CbPe6sb5KZNJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIjoHquRKZNT"
      },
      "source": [
        "## Data and Python"
      ],
      "id": "oIjoHquRKZNT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRPczDR6KZNb"
      },
      "source": [
        "### The Data\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_datasets/includes/football-data-intro.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_datasets/includes/football-data-intro.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "We’ll be using a partial EA FC 25 database for this workshop.\n",
        "\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//datasets/football-database.png\" style=\"width:60%\">\n",
        "\n",
        "Figure: <i></i>\n",
        "\n",
        "Find it in this GitHub repo: `radzim/football_data`"
      ],
      "id": "qRPczDR6KZNb"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PxPVtN4WKZNl"
      },
      "outputs": [],
      "source": [
        "import os, subprocess"
      ],
      "id": "PxPVtN4WKZNl"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7Q6as6HbKZN6"
      },
      "outputs": [],
      "source": [
        "repo_url = \"https://github.com/radzim/football_data.git\"\n",
        "repo_dir = \"football_data\"\n",
        "\n",
        "if not os.path.exists(repo_dir):\n",
        "    subprocess.run([\"git\", \"clone\", repo_url], check=True)"
      ],
      "id": "7Q6as6HbKZN6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YziYXj2wKZOK"
      },
      "source": [
        "What we have:"
      ],
      "id": "YziYXj2wKZOK"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEIoMkwoKZOQ",
        "outputId": "1ae13d7f-8351-4cc9-d790-1915bdee624a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.git',\n",
              " 'leagues.csv',\n",
              " 'teams.csv',\n",
              " 'database.xlsx',\n",
              " 'players.csv',\n",
              " 'models.csv',\n",
              " 'teamplayerlinks.csv',\n",
              " 'README.md',\n",
              " 'sofifa.csv',\n",
              " 'leagueteamlinks.csv',\n",
              " 'countries.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "os.listdir('football_data')"
      ],
      "id": "bEIoMkwoKZOQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFo0UqQ0KZOV"
      },
      "outputs": [],
      "source": [
        "with open('football_data/models.csv') as f:\n",
        "    print(f.read()[:394])"
      ],
      "id": "EFo0UqQ0KZOV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVj6uBT1KZOY"
      },
      "source": [
        "### Introduction\n",
        "\n",
        "> If you wish to make an apple pie from scratch, you must first invent\n",
        "> the universe. - *Carl Sagan*\n",
        "\n",
        "In Python we deal with information all the time. Every variable, every\n",
        "list is data stored and operated on."
      ],
      "id": "sVj6uBT1KZOY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PDagiZgHKZOb"
      },
      "outputs": [],
      "source": [
        "text = 'hello world'\n",
        "year = 2025\n",
        "primes = [2, 3, 5, 7]"
      ],
      "id": "PDagiZgHKZOb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkdtXRcSKZOe"
      },
      "source": [
        "### Memory\n",
        "\n",
        "Something not many people think about, is what these actually are, under\n",
        "the hood."
      ],
      "id": "RkdtXRcSKZOe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeKv4nRRKZOi"
      },
      "outputs": [],
      "source": [
        "True, '1', 1, 1.0"
      ],
      "id": "eeKv4nRRKZOi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQdgLmZ5KZOk"
      },
      "source": [
        "Someone coming from a C++ background, would call the above `primitives`\n",
        "- expecting them to just be raw data in memory."
      ],
      "id": "GQdgLmZ5KZOk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTp3xNKdKZOm"
      },
      "outputs": [],
      "source": [
        "type(True), type('1'), type(1), type(1.0)"
      ],
      "id": "aTp3xNKdKZOm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhZuyM16KZOp"
      },
      "source": [
        "Let’s check this assumption - we would expect a bool to take `1 bit` or\n",
        "`1 byte`, int `1-4 bytes`, string `1-2 bytes`, and float `4 bytes`"
      ],
      "id": "IhZuyM16KZOp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sB-PhfAQKZOs"
      },
      "outputs": [],
      "source": [
        "import sys"
      ],
      "id": "sB-PhfAQKZOs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VnX2JJfnKZOx"
      },
      "outputs": [],
      "source": [
        "sys.getsizeof(True), sys.getsizeof('1'), sys.getsizeof(1), sys.getsizeof(1.0)"
      ],
      "id": "VnX2JJfnKZOx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3C1hDF0KZO1"
      },
      "source": [
        "The above numbers look nothing like our predictions - why is that?\n",
        "\n",
        "Turns out, in Python, everything is actually an object. The simple `1`\n",
        "we saw above is represented in memory as:\n",
        "\n",
        "    ob_refcnt: 8 bytes\n",
        "    ob_type: 8 bytes\n",
        "    ob_size: 8 bytes (Py_ssize_t)\n",
        "    ob_digit: 4 bytes per 30 bits of int\n",
        "\n",
        "The four types above are somewhat special in Python too, with a slightly\n",
        "different implementation than other objects. Other types and structures\n",
        "are built up in similar ways, but don’t store actual values inside, but\n",
        "rather pointers to “primitives” objects.\n",
        "\n",
        "In the example above we needed 28 bytes to encode one bit of\n",
        "information. Native Python is insanely inefficient for operations on\n",
        "large data. This memory design also impacts other ways in which we\n",
        "accelerate data operations, namely caching."
      ],
      "id": "j3C1hDF0KZO1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Djc1jAgqKZO6"
      },
      "source": [
        "### Data Structures\n",
        "\n",
        "Hardware acceleration and memory layouts can only take us so far,\n",
        "usually some constant multiplier faster. For real step-changes in\n",
        "performance, we need to be mathematically clever about how we arrange\n",
        "our data."
      ],
      "id": "Djc1jAgqKZO6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kq51FnH_KZO8"
      },
      "source": [
        "### Basic data structures\n",
        "\n",
        "    list\n",
        "    tuple\n",
        "    set\n",
        "    dict\n",
        "\n",
        "By default, you would use a list for data. But other data types have\n",
        "their advantages too - set has very quick lookups, dict has quick\n",
        "lookups and stores values, and tuple is mutable and hashable (more on\n",
        "that later).\n",
        "\n",
        "Example where set massively outperforms a list:"
      ],
      "id": "Kq51FnH_KZO8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hU00CW1cKZO_"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import random"
      ],
      "id": "hU00CW1cKZO_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DXLHP9hJKZPD"
      },
      "outputs": [],
      "source": [
        "data_list = list(range(1000000))\n",
        "queries = [random.randint(0, 2000000) for _ in range(1000)]\n",
        "\n",
        "start_time = time.time()\n",
        "hits = sum(1 for q in queries if q in data_list)\n",
        "print(hits, time.time() - start_time)"
      ],
      "id": "DXLHP9hJKZPD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyuyqnUqKZPG"
      },
      "outputs": [],
      "source": [
        "data_set = set(range(1000000))\n",
        "\n",
        "start_time = time.time()\n",
        "hits = sum(1 for q in queries if q in data_set)\n",
        "print(hits, time.time() - start_time)"
      ],
      "id": "RyuyqnUqKZPG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "146HV0Y1KZPM"
      },
      "source": [
        "### Other useful data structures"
      ],
      "id": "146HV0Y1KZPM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Evd4HseVKZPN"
      },
      "source": [
        "### Counter"
      ],
      "id": "Evd4HseVKZPN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmysAzr0KZPQ"
      },
      "outputs": [],
      "source": [
        "from collections import Counter"
      ],
      "id": "KmysAzr0KZPQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aud6Igf9KZPU"
      },
      "outputs": [],
      "source": [
        "with open('football_data/leagueteamlinks.csv') as f:\n",
        "  leagues = ([x.split(',')[12] for x in f.read().split('\\n')[1:-1]]) # 13th column is leagueid\n",
        "c = Counter(leagues)\n",
        "print(c)"
      ],
      "id": "aud6Igf9KZPU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQdpg-ybKZPX"
      },
      "source": [
        "*To be expanded as I get reminded of cool things.*"
      ],
      "id": "FQdpg-ybKZPX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCuXyPpfKZPb"
      },
      "source": [
        "### Mutability"
      ],
      "id": "GCuXyPpfKZPb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7pvWspuKZPd"
      },
      "outputs": [],
      "source": [
        "l1, l2, l3 = ['apple'], ['banana'], ['cherry']\n",
        "list_of_lists = [l1, l2, l3]\n",
        "s1, s2, s3 = 'apple', 'banana', 'cherry'\n",
        "list_of_strings = [s1, s2, s3]\n",
        "print(list_of_lists, list_of_strings)"
      ],
      "id": "a7pvWspuKZPd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oa1JAZ3GKZPg"
      },
      "outputs": [],
      "source": [
        "l3[0] = 'cranberry'\n",
        "s3 = 'cranberry'\n",
        "print(l3, s3)\n",
        "print(list_of_lists)\n",
        "print(list_of_strings)"
      ],
      "id": "Oa1JAZ3GKZPg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj7IBjwWKZPk"
      },
      "source": [
        "This will be particularly important when working with Pandas, when\n",
        "operations on rows will sometimes be in-place, and sometimes return new\n",
        "objects. You will get serious silent bugs if you’re not careful."
      ],
      "id": "kj7IBjwWKZPk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaNrDdLnKZPn"
      },
      "source": [
        "### Hashability\n",
        "\n",
        "Python property, means roughly “can convert this to a number for\n",
        "lookups.”"
      ],
      "id": "jaNrDdLnKZPn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_exE1mPKZPp"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    s = {'a', 'b', 'c', ['d', 'e']}\n",
        "    print(s)\n",
        "except TypeError as e:\n",
        "    print(e)"
      ],
      "id": "p_exE1mPKZPp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_Ov9B-yKZPr"
      },
      "outputs": [],
      "source": [
        "{'a', 'b', 'c', ('d', 'e')}"
      ],
      "id": "3_Ov9B-yKZPr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCKWO5w3KZPt"
      },
      "outputs": [],
      "source": [
        "dict_ = {1: 'one', 2: 'two', (3, 4): 'three or four'}\n",
        "dict_[(3, 4)]"
      ],
      "id": "jCKWO5w3KZPt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "priPNEQUKZQo"
      },
      "source": [
        "## Spatial (and Temporal) locality\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_datasets/includes/football-spatial-temporal-locality.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_datasets/includes/football-spatial-temporal-locality.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//datasets/storage-pyramid.png\" style=\"width:60%\">\n",
        "\n",
        "Figure: <i></i>\n",
        "\n",
        "Spatial locality means a program is likely to access nearby memory\n",
        "addresses soon after accessing one (e.g., iterating through an array).\n",
        "CPUs exploit both by loading data from RAM based on expected patterns of\n",
        "use.\n",
        "\n",
        "Temporal locality benefits from keeping recently used data in cache,\n",
        "while spatial locality benefits from prefetching adjacent data to speed\n",
        "up sequential access.\n",
        "\n",
        "Let’s test it out using a toy example - summing over 1m numbers, first\n",
        "in order, then randomly."
      ],
      "id": "priPNEQUKZQo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNpKL9VfKZQr"
      },
      "outputs": [],
      "source": [
        "import time"
      ],
      "id": "hNpKL9VfKZQr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zynOdryeKZQu"
      },
      "outputs": [],
      "source": [
        "arr = [1]*10000000\n",
        "indices = list(range(10000000))\n",
        "start_time = time.time()\n",
        "s = 0\n",
        "for i in indices:\n",
        "    s += arr[i]\n",
        "print(s, time.time()-start_time)"
      ],
      "id": "zynOdryeKZQu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAsHg4XPKZQx"
      },
      "outputs": [],
      "source": [
        "import random"
      ],
      "id": "FAsHg4XPKZQx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ggFjRgtKZQ0"
      },
      "outputs": [],
      "source": [
        "arr = [1]*10000000\n",
        "indices = list(range(10000000))\n",
        "random.shuffle(indices)\n",
        "start_time = time.time()\n",
        "s = 0\n",
        "for i in indices:\n",
        "    s += arr[i]\n",
        "print(s, time.time()-start_time)"
      ],
      "id": "8ggFjRgtKZQ0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cC8kzHsfKZQ3"
      },
      "source": [
        "Mathematically speaking, these two operations are the same. Yet one\n",
        "takes about 5-10 times longer. This is exactly due to locality - it’s\n",
        "much faster to read data that’s right next to each other in memory.\n",
        "\n",
        "Python’s huge representations of data, and overused pointers, limit the\n",
        "capabilities of caching.\n",
        "\n",
        "It is a little bit silly to be optimising Python code, given how much\n",
        "inefficiency our choice of language brings on, but the considerations\n",
        "are still important, and translate to other systems you may build."
      ],
      "id": "cC8kzHsfKZQ3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ykCjKYqVKZQ6"
      },
      "outputs": [],
      "source": [
        "# temporal locality would be this - difference is quite small\n",
        "# import time\n",
        "# arr = [1]*10000000\n",
        "# indices = [1]*10000000\n",
        "# start_time = time.time()\n",
        "# s = 0\n",
        "# for i in indices:\n",
        "#     s += arr[i]\n",
        "# print(s, time.time()-start_time)"
      ],
      "id": "ykCjKYqVKZQ6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7x3XNzPKZQ_"
      },
      "source": [
        "### Numerical Computation `np`"
      ],
      "id": "r7x3XNzPKZQ_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xrZkTT8FKZRB"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ],
      "id": "xrZkTT8FKZRB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQgK3JO2KZRE"
      },
      "source": [
        "Probably all of you have written the above line hundreds of times. Let’s\n",
        "recap why we do it.\n",
        "\n",
        "NumPy is a Python library for fast numerical computing. It’s the\n",
        "foundation for many data science and machine learning libraries,\n",
        "including Pandas. Under the hood, NumPy is written largely in C to\n",
        "achieve high performance."
      ],
      "id": "QQgK3JO2KZRE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCj1tVQzKZRI"
      },
      "outputs": [],
      "source": [
        "arr = [1]*10000000\n",
        "indices = list(range(10000000))\n",
        "start_time = time.time()\n",
        "s = 0\n",
        "for i in indices:\n",
        "    s += arr[i]\n",
        "print(s, time.time()-start_time)\n",
        "\n",
        "np_arr = np.array(arr)\n",
        "start_time = time.time()\n",
        "s = np_arr.sum()\n",
        "print(s, time.time()-start_time)"
      ],
      "id": "rCj1tVQzKZRI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKtSAwB1KZRL"
      },
      "source": [
        "NumPy is insanely fast. Use it everywhere you can!"
      ],
      "id": "pKtSAwB1KZRL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofJqJh43KZRP"
      },
      "source": [
        "### Cheat Sheet\n",
        "\n",
        "Create Arrays\n",
        "\n",
        "    a = np.array([1, 2, 3, 4, 5])\n",
        "    print(a)        # [1 2 3 4 5]\n",
        "    print(a.shape)  # (5,)\n",
        "\n",
        "Multidimensional array:\n",
        "\n",
        "    b = np.array([[1, 2, 3],\n",
        "                  [4, 5, 6]])\n",
        "    print(b)\n",
        "    # [[1 2 3]\n",
        "    #  [4 5 6]]\n",
        "    print(b.shape)  # (2, 3)\n",
        "\n",
        "Array Slicing\n",
        "\n",
        "    arr = np.array([10, 20, 30, 40, 50])\n",
        "    print(arr[1:4])   # [20 30 40]\n",
        "    print(arr[:3])    # [10 20 30]\n",
        "    print(arr[-2:])   # [40 50]\n",
        "\n",
        "2D slicing:\n",
        "\n",
        "    b = np.array([[1, 2, 3],\n",
        "                  [4, 5, 6],\n",
        "                  [7, 8, 9]])\n",
        "    print(b[0:2, 1:3])\n",
        "    # [[2 3]\n",
        "    #  [5 6]]\n",
        "\n",
        "Fancy Indexing & Boolean Masking\n",
        "\n",
        "    arr = np.array([5, 10, 15, 20, 25])\n",
        "    print(arr[[0, 2, 4]])    # [ 5 15 25]\n",
        "    print(arr[arr > 10])     # [15 20 25]\n",
        "\n",
        "Vectorized Operations\n",
        "\n",
        "    x = np.array([1, 2, 3])\n",
        "    y = np.array([10, 20, 30])\n",
        "\n",
        "    print(x + y)    # [11 22 33]\n",
        "    print(x * y)    # [10 40 90]\n",
        "    print(x ** 2)   # [1 4 9]\n",
        "\n",
        "Cumulative Sum & Other Reductions\n",
        "\n",
        "    arr = np.array([1, 2, 3, 4])\n",
        "    print(np.cumsum(arr))  # [ 1  3  6 10]\n",
        "    print(np.sum(arr))     # 10\n",
        "    print(np.prod(arr))    # 24\n",
        "    print(np.mean(arr))    # 2.5\n",
        "\n",
        "Reshaping Arrays\n",
        "\n",
        "    arr = np.arange(1, 13)\n",
        "    reshaped = arr.reshape(3, 4)\n",
        "    print(reshaped)\n",
        "    # [[ 1  2  3  4]\n",
        "    #  [ 5  6  7  8]\n",
        "    #  [ 9 10 11 12]]\n",
        "\n",
        "Useful Utilities\n",
        "\n",
        "    np.zeros((2, 3))     # [[0. 0. 0.]\n",
        "                         #  [0. 0. 0.]]\n",
        "    np.ones((2, 3))      # [[1. 1. 1.]\n",
        "                         #  [1. 1. 1.]]\n",
        "    np.arange(0, 10, 2)  # [0 2 4 6 8]\n",
        "    np.linspace(0, 1, 5) # [0.   0.25 0.5  0.75 1. ]"
      ],
      "id": "ofJqJh43KZRP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAzcbbksKZRT"
      },
      "source": [
        "### Structured Data `pd`"
      ],
      "id": "SAzcbbksKZRT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3rGmYWbKZRX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ],
      "id": "b3rGmYWbKZRX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2ONMo1XKZRa"
      },
      "source": [
        "Again, probably all of you have written the above line hundreds of\n",
        "times. Let’s recap why we do it.\n",
        "\n",
        "Pandas is a library built on top of NumPy. It provides two main data\n",
        "structures: Series (1D) and DataFrame (2D) to handle structured data\n",
        "efficiently.\n",
        "\n",
        "Pandas supports data cleaning, transformation, aggregation, merging,\n",
        "time-series analysis, and visualisation with minimal code. It integrates\n",
        "neatly with common libraries (`np`, `plt`, `sk`, …).\n",
        "\n",
        "It moves all numerical operations to NumPy, for great speed. It also has\n",
        "builtin support for tonnes of data formats, like `csv`, `xlsx`, `db` … .\n",
        "\n",
        "One of the most used tools in data science and machine learning."
      ],
      "id": "T2ONMo1XKZRa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoH7cYKFKZRd"
      },
      "source": [
        "### Cheat Sheet\n",
        "\n",
        "Create DataFrames\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        \"playerid\": [1, 2, 3, 4],\n",
        "        \"playername\": [\"Messi\", \"Ronaldo\", \"Mbappe\", \"Haaland\"],\n",
        "        \"height\": [170, 187, 178, 195]\n",
        "    })\n",
        "    print(df)\n",
        "\n",
        "Read & Inspect Data\n",
        "\n",
        "    df = pd.read_csv(\"football_data/players.csv\")\n",
        "    print(df.head())      # First 5 rows\n",
        "    print(df.info())      # Column info & types\n",
        "    print(df.describe())  # Stats summary for numeric columns\n",
        "    print(df.columns)     # List of column names\n",
        "    print(df.shape)       # (rows, columns)\n",
        "\n",
        "Selecting Columns & Rows\n",
        "\n",
        "    df[\"playername\"]                  # Single column - Series\n",
        "    df[[\"playername\", \"height\"]]      # Multiple columns\n",
        "\n",
        "    df.iloc[0]          # by position\n",
        "    df.loc[0]           # by label\n",
        "    df.iloc[0:3]        # First 3 rows\n",
        "    df.loc[df[\"height\"] > 185]   # Conditional filter\n",
        "\n",
        "Sorting\n",
        "\n",
        "    df.sort_values(\"height\", ascending=False).head()\n",
        "\n",
        "Grouping & Aggregation\n",
        "\n",
        "    df.groupby(\"nationality\")[\"height\"].mean()\n",
        "\n",
        "Merging & Joining\n",
        "\n",
        "    teamplayerlinks = pd.read_csv(\"football_data/teamplayerlinks.csv\")\n",
        "    df_merged = df.merge(teamplayerlinks, on=\"playerid\", how=\"left\")\n",
        "    print(df_merged.head())\n",
        "\n",
        "Missing Data\n",
        "\n",
        "    df.isna().sum()\n",
        "    df[\"height\"].fillna(df[\"height\"].mean())\n",
        "    df.dropna(subset=[\"height\"])\n",
        "\n",
        "Exporting Data\n",
        "\n",
        "    df.to_csv(\"players_clean.csv\", index=False)\n",
        "    df.to_pickle(\"players_clean.pkl\")\n",
        "\n",
        "Avoiding mutability issues\n",
        "\n",
        "    df2 = df.copy()"
      ],
      "id": "YoH7cYKFKZRd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaEkv_QLKZRh"
      },
      "source": [
        "### Apply"
      ],
      "id": "UaEkv_QLKZRh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i4vilSWfKZRj"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('football_data/players.csv')\n",
        "start = time.time()\n",
        "df[\"height_m\"] = df[\"height\"].map(lambda x: x / 100)\n",
        "df[\"bmi\"] = df.apply(lambda x: x[\"weight\"]/x[\"height_m\"]**2, axis=1)\n",
        "print(time.time()-start)\n",
        "df[\"bmi\"]\n",
        "# .map is very similar to `apply` for Series, slightly faster, accepts a dictionary too not just function"
      ],
      "id": "i4vilSWfKZRj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1X-KmKThKZRm"
      },
      "source": [
        "Caveat: Apply is not vectorised, not very fast. Use vectorised\n",
        "operations where possible!"
      ],
      "id": "1X-KmKThKZRm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7S1kZi81KZRr"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('football_data/players.csv')\n",
        "start = time.time()\n",
        "df[\"height_m\"] = df[\"height\"]/100\n",
        "df[\"bmi\"] = df[\"weight\"]/df[\"height_m\"]**2\n",
        "print(time.time()-start)\n",
        "df[\"bmi\"]"
      ],
      "id": "7S1kZi81KZRr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o4V7gMwKZRt"
      },
      "source": [
        "## Pickles\n",
        "\n",
        "Pickles are a Python way of storing objects as files. Very useful, and\n",
        "usually faster than the naive way of doing things."
      ],
      "id": "7o4V7gMwKZRt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-eT3yVZKZRv"
      },
      "outputs": [],
      "source": [
        "t = time.time()\n",
        "df.to_csv(\"data.csv\")\n",
        "pd.read_csv(\"data.csv\")\n",
        "print(\"csv\", time.time() - t)\n",
        "\n",
        "t = time.time()\n",
        "df.to_pickle(\"data.pkl\")\n",
        "pd.read_pickle(\"data.pkl\")\n",
        "print(\"pickle\", time.time() - t)"
      ],
      "id": "d-eT3yVZKZRv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUzVl7aQKZRy"
      },
      "source": [
        "Pickle are very general and can store basically any Python object, even\n",
        "functions."
      ],
      "id": "vUzVl7aQKZRy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UM6fQq9XKZR1"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ],
      "id": "UM6fQq9XKZR1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gmbUOBQKZR5"
      },
      "outputs": [],
      "source": [
        "def greet(name): return f\"Hello, {name}!\"\n",
        "pickle.dump(greet, open(\"func.pkl\", \"wb\"))\n",
        "f = pickle.load(open(\"func.pkl\", \"rb\"))\n",
        "print(f(\"World\"))"
      ],
      "id": "2gmbUOBQKZR5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2R6QrmE2KZR8"
      },
      "source": [
        "### Databases `sql`\n",
        "\n",
        "You should already know this from previous courses, but here’s a little\n",
        "recap."
      ],
      "id": "2R6QrmE2KZR8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujJdFX2wKZSA"
      },
      "source": [
        "### Cheat Sheet\n",
        "\n",
        "Create Tables & Insert Data\n",
        "\n",
        "    CREATE TABLE players (\n",
        "        playerid INTEGER PRIMARY KEY,\n",
        "        playername TEXT,\n",
        "        height INTEGER\n",
        "    );\n",
        "    INSERT INTO players (playerid, playername, height) VALUES\n",
        "    (1, 'Messi', 170),\n",
        "    (2, 'Ronaldo', 187),\n",
        "    (3, 'Mbappe', 178),\n",
        "    (4, 'Haaland', 195);\n",
        "\n",
        "Read & Inspect Data\n",
        "\n",
        "    SELECT * FROM players LIMIT 5;\n",
        "    SELECT COUNT(*) FROM players;\n",
        "    PRAGMA table_info(players);\n",
        "    SELECT name FROM sqlite_master WHERE type='table';\n",
        "\n",
        "Selecting Columns & Rows\n",
        "\n",
        "    SELECT playername FROM players;\n",
        "    SELECT playername, height FROM players;\n",
        "    SELECT * FROM players WHERE playerid = 1;\n",
        "    SELECT * FROM players WHERE height > 185;\n",
        "    SELECT * FROM players LIMIT 3;\n",
        "\n",
        "Sorting\n",
        "\n",
        "    SELECT * FROM players\n",
        "    ORDER BY height DESC\n",
        "    LIMIT 5;\n",
        "\n",
        "Grouping & Aggregation\n",
        "\n",
        "    SELECT nationality, AVG(height) AS avg_height\n",
        "    FROM players\n",
        "    GROUP BY nationality;\n",
        "\n",
        "    SELECT teamid, COUNT(*) AS num_players\n",
        "    FROM teamplayerlinks\n",
        "    GROUP BY teamid;\n",
        "\n",
        "Joining Tables\n",
        "\n",
        "    SELECT p.playerid, p.playername, p.height, t.teamid\n",
        "    FROM players AS p\n",
        "    LEFT JOIN teamplayerlinks AS t\n",
        "        ON p.playerid = t.playerid\n",
        "    LIMIT 5;\n",
        "\n",
        "Handling Missing / NULL Values\n",
        "\n",
        "    SELECT * FROM players WHERE height IS NULL;\n",
        "    UPDATE players\n",
        "    SET height = (SELECT AVG(height) FROM players)\n",
        "    WHERE height IS NULL;\n",
        "    DELETE FROM players WHERE height IS NULL;\n",
        "\n",
        "Exporting Data (from CLI)\n",
        "\n",
        "    .headers on\n",
        "    .mode csv\n",
        "    .output players_clean.csv\n",
        "    SELECT * FROM players;\n",
        "    .output stdout\n",
        "\n",
        "Nested\n",
        "\n",
        "    SELECT * FROM players\n",
        "    WHERE playerid IN (\n",
        "      SELECT playerid FROM teamplayerlinks WHERE teamid = 10\n",
        "    );\n",
        "\n",
        "Indexing and Query Planning\n",
        "\n",
        "    CREATE INDEX idx_players_height ON players(height);\n",
        "    CREATE INDEX idx_tpl_player ON teamplayerlinks(playerid);\n",
        "    CREATE INDEX idx_tpl_team_player ON teamplayerlinks(teamid, playerid);"
      ],
      "id": "ujJdFX2wKZSA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5oCyoT_KZSE"
      },
      "source": [
        "## SQL in Python\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_data-science/includes/football-sql-in-python.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/football-sql-in-python.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "Just a reminder, you can use SQL inside Python very neatly. It’s the\n",
        "recommended practice, and leaves you compatible with other systems using\n",
        "your database."
      ],
      "id": "e5oCyoT_KZSE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V13Fp2EjKZSH"
      },
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "import pandas as pd"
      ],
      "id": "V13Fp2EjKZSH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jkvrwqdKZSL"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"football_data/players.csv\")\n",
        "conn = sqlite3.connect(\"example.db\")\n",
        "cur = conn.cursor()\n",
        "\n",
        "cur.execute(\"DROP TABLE IF EXISTS players\")\n",
        "df.to_sql(\"players\", conn, if_exists=\"replace\", index=False)\n",
        "\n",
        "for row in cur.execute(\"SELECT playerid FROM players WHERE potential > 92\"):\n",
        "    print(row)\n",
        "\n",
        "cur.close()\n",
        "conn.close()"
      ],
      "id": "4jkvrwqdKZSL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60JPbpz4KZSP"
      },
      "source": [
        "### Credential Storage\n",
        "\n",
        "Many times when working with APIs and non-public data, you will use\n",
        "passwords, usernames, keys. It’s commonplace to just leave them in the\n",
        "notebook, but that’s a horrible idea, for obvious reasons.\n",
        "\n",
        "Better way is to set the values as environment variables. Ideally you\n",
        "would set them in your system, like:\n",
        "\n",
        "    set API_KEY=your_api_key_here\n",
        "    set DB_PASSWORD=your_db_password\n",
        "\n",
        "Or in Python:"
      ],
      "id": "60JPbpz4KZSP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUhW8lZmKZSU"
      },
      "outputs": [],
      "source": [
        "os.environ[\"API_KEY\"] = \"my_secret_key\"\n",
        "os.environ[\"DB_PASSWORD\"] = \"super_secret\"\n",
        "# remember to remove this from anything someone else might have access to,\n",
        "# including autosave and version control!\n",
        "\n",
        "print(os.getenv(\"API_KEY\"))\n",
        "print(os.getenv(\"DB_PASSWORD\"))"
      ],
      "id": "gUhW8lZmKZSU"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bafZWtOsKZSX"
      },
      "source": [
        "The above might be very annoying when working in a notebook where we\n",
        "keep resetting runtime, with you having to re-type the environment\n",
        "variables again and again.\n",
        "\n",
        "A middle-ground between security and usability."
      ],
      "id": "bafZWtOsKZSX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3SiXCfZKZSc"
      },
      "outputs": [],
      "source": [
        "import json"
      ],
      "id": "Y3SiXCfZKZSc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTi1YQiQKZSg"
      },
      "outputs": [],
      "source": [
        "secrets = {\n",
        "    \"API_KEY\": \"my_secret_key\", # remember to remove, or ideally edit in file only\n",
        "    \"DB_PASSWORD\": \"super_secret\" # remember to remove, or ideally edit in file only\n",
        "}\n",
        "with open(\"secrets.json\", \"w\") as f:\n",
        "    json.dump(secrets, f, indent=4)"
      ],
      "id": "CTi1YQiQKZSg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suyqel68KZSj"
      },
      "outputs": [],
      "source": [
        "with open(\"secrets.json\") as f:\n",
        "    loaded = json.load(f)\n",
        "\n",
        "print(\"API_KEY:\", loaded[\"API_KEY\"])\n",
        "print(\"DB_PASSWORD:\", loaded[\"DB_PASSWORD\"])\n",
        "# remember to not have outputs like this in anything visible to others"
      ],
      "id": "suyqel68KZSj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZoGud5GJKZSl"
      },
      "source": [
        "`.env` files and the `dotenv` library is also a less intuitive but more\n",
        "professional way to do it.\n",
        "\n",
        "You can also use `input`\n",
        "\n",
        "    api_key = input(\"Enter API key: \")\n",
        "    db_password = input(\"Enter DB password: \")\n",
        "\n",
        "or IPython interact\n",
        "\n",
        "    import ipywidgets as w\n",
        "    from IPython.display import display\n",
        "\n",
        "    api_key = w.Text(description=\"API Key\")\n",
        "    db_password = w.Password(description=\"Password\")\n",
        "\n",
        "    display(api_key, db_password)\n",
        "    # api_key.value\n",
        "    # db_password.value\n",
        "\n",
        "as other means of not leaving passwords in your notebook."
      ],
      "id": "ZoGud5GJKZSl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_4RMVBhKZSo"
      },
      "source": [
        "### Indexing"
      ],
      "id": "K_4RMVBhKZSo"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DdZx70iKZSr"
      },
      "source": [
        "### Background\n",
        "\n",
        "A database is not a special piece of hardware, it can live on any\n",
        "medium. It’s just an organized collection of data stored in a structured\n",
        "way, allowing efficient storage, retrieval, and management of\n",
        "information.\n",
        "\n",
        "What we usually mean by a database is just a standard digital\n",
        "implementation of such a system.\n",
        "\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//datasets/british-geological-survey.jpg\" style=\"width:\">\n",
        "\n",
        "Figure: <i>50%</i>\n",
        "\n",
        "What makes databases special is the structure - the information is\n",
        "conveyed in a way that allows for complicated lookup operations to be\n",
        "completed quickly."
      ],
      "id": "2DdZx70iKZSr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKBOUETVKZSv"
      },
      "source": [
        "### Physical Index\n",
        "\n",
        "This is what you would usually mean when talking about simple indexes.\n",
        "This is how dictionaries, encyclopedias work. Many datasets have\n",
        "built-in physical indices, even if not explicitly defined.\n",
        "\n",
        "In our example, we can see that some tables are sorted by an important\n",
        "column - eg. `models.csv` is sorted by `playerid`. We can use this to\n",
        "our advantage when searching through it.\n",
        "\n",
        "Without abstracting away to library search functions, let’s follow\n",
        "through on what it might look like to find who is player `188545`."
      ],
      "id": "fKBOUETVKZSv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3xUsArKKZSx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ],
      "id": "C3xUsArKKZSx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hn0Faw4SKZSz"
      },
      "outputs": [],
      "source": [
        "models_df = pd.read_csv('football_data/models.csv')\n",
        "\n",
        "start = time.time()\n",
        "search_id = 188545\n",
        "for i in range(len(models_df)):\n",
        "    if models_df.iloc[i]['playerid'] == search_id:\n",
        "        print(models_df.iloc[i]['playername'])\n",
        "print(time.time()-start)"
      ],
      "id": "hn0Faw4SKZSz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYV8iBkKKZS1"
      },
      "source": [
        "Now, let’s assume the table is sorted on `playerid`. This allows us to\n",
        "search through the data cleverly, only checking a couple values."
      ],
      "id": "kYV8iBkKKZS1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roN0AmHoKZS3"
      },
      "outputs": [],
      "source": [
        "models_df = pd.read_csv('football_data/models.csv')\n",
        "start = time.time()\n",
        "search_id = 188545\n",
        "left, right = 0, len(models_df) - 1\n",
        "while left <= right:\n",
        "    mid = (left + right) // 2\n",
        "    val = models_df.iloc[mid]['playerid']\n",
        "    if val == search_id:\n",
        "        print(models_df.iloc[mid]['playername'])\n",
        "        break\n",
        "    elif val < search_id:\n",
        "        left = mid + 1\n",
        "    else:\n",
        "        right = mid - 1\n",
        "print(time.time() - start)"
      ],
      "id": "roN0AmHoKZS3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeLzgViIKZS6"
      },
      "source": [
        "The above is not *truly* an index, as many `playerids` are missing, so\n",
        "we can’t just look up the 188545th row instantly - we still used\n",
        "`O(log(n))` lookups. Proper indexing will allow us to do that."
      ],
      "id": "MeLzgViIKZS6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4GO4J1TKZTC"
      },
      "outputs": [],
      "source": [
        "models_df_indexed = pd.read_csv('football_data/models.csv').set_index('playerid')\n",
        "start = time.time()\n",
        "search_id = 188545\n",
        "print(models_df_indexed.loc[search_id]['playername'])\n",
        "print(time.time() - start)"
      ],
      "id": "H4GO4J1TKZTC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKv0WNfoKZTF"
      },
      "source": [
        "### Logical index\n",
        "\n",
        "A logical index is an external structure that we build next to our\n",
        "database. Pandas doesn’t really allow that (limit 1 index), but you can\n",
        "use as many as you want in SQL.\n",
        "\n",
        "Let’s demonstrate a home-made logical index on the same dataframe, where\n",
        "we index the player names, for a quick `playername -> playerid` search."
      ],
      "id": "WKv0WNfoKZTF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRaJyTWTKZTH"
      },
      "outputs": [],
      "source": [
        "name_to_index = {name: i for i, name in enumerate(models_df_indexed['playername'])}\n",
        "start = time.time()\n",
        "models_df_indexed.iloc[name_to_index['Robert Lewandowski']]\n",
        "print(time.time() - start)"
      ],
      "id": "aRaJyTWTKZTH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUPuudg1KZTJ"
      },
      "source": [
        "Databases will do that under the hood for you, just use SQL like:\n",
        "\n",
        "    CREATE INDEX index_name\n",
        "    ON table_name (column1, column2, ...);"
      ],
      "id": "DUPuudg1KZTJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZSgSzIBKZTR"
      },
      "source": [
        "### Practical example\n",
        "\n",
        "Let’s load in the `players`, `teams`, and `teamplayerlinks` tables we\n",
        "have, to a new database."
      ],
      "id": "MZSgSzIBKZTR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eok194sLKZTV"
      },
      "outputs": [],
      "source": [
        "db_path = \"football.db\"\n",
        "players_csv = \"football_data/players.csv\"\n",
        "teams_csv = \"football_data/teams.csv\"\n",
        "teamlinks_csv = \"football_data/teamplayerlinks.csv\"\n",
        "\n",
        "conn = sqlite3.connect(db_path)\n",
        "\n",
        "players_df = pd.read_csv(players_csv)\n",
        "teams_df = pd.read_csv(teams_csv)\n",
        "teamlinks_df = pd.read_csv(teamlinks_csv)\n",
        "\n",
        "players_df.to_sql(\"players\", conn, if_exists=\"replace\", index=False)\n",
        "teams_df.to_sql(\"teams\", conn, if_exists=\"replace\", index=False)\n",
        "teamlinks_df.to_sql(\"teamplayerlinks\", conn, if_exists=\"replace\", index=False)\n",
        "\n",
        "cur = conn.cursor()"
      ],
      "id": "eok194sLKZTV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSy6jTDBKZTY"
      },
      "outputs": [],
      "source": [
        "query = \"\"\"\n",
        "SELECT p.overallrating\n",
        "FROM players p\n",
        "JOIN teamplayerlinks tpl ON p.playerid = tpl.playerid\n",
        "JOIN teams t ON tpl.teamid = t.teamid\n",
        "WHERE t.teamname = \"Sheffield Utd\";\n",
        "\"\"\"\n",
        "\n",
        "start = time.time()\n",
        "cur.execute(query)\n",
        "results = [row[0] for row in cur.fetchall()]\n",
        "print(time.time() - start)\n",
        "\n",
        "print(results)"
      ],
      "id": "YSy6jTDBKZTY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Acl5UJveKZTa"
      },
      "source": [
        "Now, let’s make indices on `teamid` and `playerid` (others optional)."
      ],
      "id": "Acl5UJveKZTa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukqn7ZYVKZTf"
      },
      "outputs": [],
      "source": [
        "queries = [\n",
        "    \"CREATE INDEX IF NOT EXISTS idx_teams_teamname ON teams(teamname);\",\n",
        "    \"CREATE INDEX IF NOT EXISTS idx_tpl_teamid ON teamplayerlinks(teamid);\",\n",
        "    \"CREATE INDEX IF NOT EXISTS idx_tpl_playerid ON teamplayerlinks(playerid);\",\n",
        "    \"CREATE INDEX IF NOT EXISTS idx_players_playerid ON players(playerid);\"\n",
        "]\n",
        "\n",
        "for q in queries:\n",
        "    cur.execute(q)"
      ],
      "id": "ukqn7ZYVKZTf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLvWb2LAKZTh"
      },
      "source": [
        "And now, let’s call the same query we did before. This should be\n",
        "massively faster."
      ],
      "id": "sLvWb2LAKZTh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWWHq1aFKZTj"
      },
      "outputs": [],
      "source": [
        "query = \"\"\"\n",
        "SELECT p.overallrating\n",
        "FROM players p\n",
        "JOIN teamplayerlinks tpl ON p.playerid = tpl.playerid\n",
        "JOIN teams t ON tpl.teamid = t.teamid\n",
        "WHERE t.teamname = \"Sheffield Utd\";\n",
        "\"\"\"\n",
        "\n",
        "start = time.time()\n",
        "cur.execute(query)\n",
        "results = [row[0] for row in cur.fetchall()]\n",
        "print(time.time() - start)\n",
        "\n",
        "print(results)"
      ],
      "id": "QWWHq1aFKZTj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xJllihAKZTm"
      },
      "source": [
        "## Multi-column Index\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_data-science/includes/football-multi-column-index.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_data-science/includes/football-multi-column-index.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "Sometimes you will be repetitively looking for data that fits multiple\n",
        "criteria at once. The most common example would be coordinates -\n",
        "latitude and longitude.\n",
        "\n",
        "Imagine if, when looking for houses within 10km of Mt Kenya, you had to\n",
        "search through all the houses on earth one by one. That would be very\n",
        "inefficient. But single indices on latitude and longitude would still\n",
        "not help you that much - there are millions of houses within 10km of the\n",
        "equator, in Congo, Ecuador, Indonesia - you would first narrow it down\n",
        "to all of those, and then have to search through them again, with\n",
        "respect to longitude.\n",
        "\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//datasets/world-map-continents-oceans.png\" style=\"width:80%\">\n",
        "\n",
        "Figure: <i></i>\n",
        "\n",
        "That’s why we have multi-column indices. The simplest example would be a\n",
        "map - given a detailed map, I can easily find the area I’m looking for\n",
        "data in.\n",
        "\n",
        "Using our `players` example, let’s look for players who are both tall\n",
        "and strong."
      ],
      "id": "9xJllihAKZTm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssp_aXLsKZTp"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "query = \"\"\"\n",
        "SELECT playerid, height, strength\n",
        "FROM players\n",
        "WHERE height > 190 AND strength > 90\n",
        "\"\"\"\n",
        "cur.execute(query)\n",
        "results = cur.fetchall()\n",
        "print(time.time() - start)\n",
        "\n",
        "print(len(results))"
      ],
      "id": "ssp_aXLsKZTp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VfYnt2oKZTs"
      },
      "source": [
        "Now, if we set individual indices, this becomes much faster:"
      ],
      "id": "2VfYnt2oKZTs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAPQeB81KZTv"
      },
      "outputs": [],
      "source": [
        "queries = [\n",
        "    \"CREATE INDEX IF NOT EXISTS idx_players_height ON players(height);\",\n",
        "    \"CREATE INDEX IF NOT EXISTS idx_players_strength ON players(strength);\",\n",
        "]\n",
        "\n",
        "for q in queries:\n",
        "    cur.execute(q)"
      ],
      "id": "EAPQeB81KZTv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRy7LieoKZTy"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "query = \"\"\"\n",
        "SELECT playerid, height, strength\n",
        "FROM players\n",
        "WHERE height > 190 AND strength > 90\n",
        "\"\"\"\n",
        "cur.execute(query)\n",
        "results = cur.fetchall()\n",
        "print(time.time() - start)\n",
        "\n",
        "print(len(results))"
      ],
      "id": "tRy7LieoKZTy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33uz1KTIKZT1"
      },
      "outputs": [],
      "source": [
        "queries = [\n",
        "\"CREATE INDEX idx_players_height_strength ON players(height, strength);\"\n",
        "]\n",
        "\n",
        "for q in queries:\n",
        "    cur.execute(q)"
      ],
      "id": "33uz1KTIKZT1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "41IgbDtHKZT5"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "query = \"\"\"\n",
        "SELECT playerid, height, strength\n",
        "FROM players\n",
        "WHERE height > 190 AND strength > 90\n",
        "\"\"\"\n",
        "cur.execute(query)\n",
        "results = cur.fetchall()\n",
        "print(time.time() - start)\n",
        "\n",
        "print(len(results))"
      ],
      "id": "41IgbDtHKZT5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwlUEns6KZT9"
      },
      "source": [
        "Looks like this is not actually that good of an example - performance\n",
        "didn’t change much, maybe actually got worse. Don’t be alarmed, this is\n",
        "just because our table is quite small (27000 rows), and traversing the\n",
        "indices takes more time than just reading the table. The difference will\n",
        "be huge on larger datasets though, so remember about these!\n",
        "\n",
        "Remember to close the connection"
      ],
      "id": "kwlUEns6KZT9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6XxUJhbKZUC"
      },
      "outputs": [],
      "source": [
        "conn.close()"
      ],
      "id": "n6XxUJhbKZUC"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLwOYckEKZUE"
      },
      "source": [
        "### Pandas MultiIndex\n",
        "\n",
        "Despite similar name, and pertaining to similar things, a Pandas\n",
        "MultiIndex is not what we described above. It’s not an index where you\n",
        "can search over multiple columns, but rather a *hierarchical* index,\n",
        "where you’re looking over multiple columns as if they were one key."
      ],
      "id": "xLwOYckEKZUE"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h_dxaZQCKZUH"
      },
      "outputs": [],
      "source": [
        "tpl_df = pd.read_csv('football_data/teamplayerlinks.csv')\n",
        "tpl_df = tpl_df.set_index(['teamid', 'jerseynumber'])\n",
        "tpl_df = tpl_df.sort_index()\n",
        "tpl_df.tail()"
      ],
      "id": "h_dxaZQCKZUH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCZiENuHKZUK"
      },
      "source": [
        "Then, we can neatly look up the stats of the player who plays with `#9`\n",
        "for team `241 - FC Barcelona`."
      ],
      "id": "sCZiENuHKZUK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDX6IRxEKZUN"
      },
      "outputs": [],
      "source": [
        "tpl_df.loc[241, 9]"
      ],
      "id": "DDX6IRxEKZUN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEohntRDKZUQ"
      },
      "source": [
        "This falls in the *syntactic sugar* category of things, not really\n",
        "improving performace, just allowing for neat code."
      ],
      "id": "TEohntRDKZUQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpxWgesjKZUT"
      },
      "source": [
        "### Plotting `plt`"
      ],
      "id": "LpxWgesjKZUT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xGmZ_gcKZUV"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "id": "5xGmZ_gcKZUV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kWDU9nGKZUX"
      },
      "source": [
        "Matplotlib is a plotting library, used by nearly everyone. Inspired by\n",
        "matlab.\n",
        "\n",
        "Support for many types of plots, lot of flexibility in options, but also\n",
        "short minimal required code."
      ],
      "id": "6kWDU9nGKZUX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvjKC_JvKZUZ"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"football_data/players.csv\")\n",
        "\n",
        "plt.scatter(df['acceleration'], df['sprintspeed'])\n",
        "plt.show()"
      ],
      "id": "XvjKC_JvKZUZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08w28rCuKZUc"
      },
      "source": [
        "Lot’s of things to improve on, even in such a simple chart. Remember\n",
        "that at the end, half of your reader’s attention will go to charts. You\n",
        "should give some thought to make sure they show what you want them to,\n",
        "clearly and legibly."
      ],
      "id": "08w28rCuKZUc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShmBLynfKZUg"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(df['acceleration'], df['sprintspeed'], alpha=0.05, color='blue', edgecolors='none')\n",
        "\n",
        "plt.xlabel(\"Acceleration\")\n",
        "plt.ylabel(\"Sprint Speed\")\n",
        "plt.title(\"Acceleration vs Sprint Speed\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "id": "ShmBLynfKZUg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vXTvc-7KZUj"
      },
      "source": [
        "### Cheat Sheet\n",
        "\n",
        "Basic Line Plot\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    x = [1, 2, 3, 4, 5]\n",
        "    y = [2, 4, 6, 8, 10]\n",
        "\n",
        "    plt.plot(x, y)\n",
        "    plt.show()\n",
        "\n",
        "Scatter Plot\n",
        "\n",
        "    plt.scatter(df['acceleration'], df['sprintspeed'], alpha=0.2)\n",
        "    plt.xlabel(\"Acceleration\")\n",
        "    plt.ylabel(\"Sprint Speed\")\n",
        "    plt.title(\"Acceleration vs Sprint Speed\")\n",
        "    plt.show()\n",
        "\n",
        "Bar Chart\n",
        "\n",
        "    categories = ['A', 'B', 'C']\n",
        "    values = [4, 7, 3]\n",
        "\n",
        "    plt.bar(categories, values)\n",
        "    plt.xlabel(\"Category\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    plt.title(\"Bar Chart Example\")\n",
        "    plt.show()\n",
        "\n",
        "Histogram\n",
        "\n",
        "    data = [1, 2, 2, 3, 3, 3, 4, 4, 4, 4]\n",
        "\n",
        "    plt.hist(data, bins=4, edgecolor='black')\n",
        "    plt.xlabel(\"Bins\")\n",
        "    plt.ylabel(\"Frequency\")\n",
        "    plt.title(\"Histogram Example\")\n",
        "    plt.show()\n",
        "\n",
        "Pie Chart\n",
        "\n",
        "    sizes = [30, 40, 20, 10]\n",
        "    labels = ['A', 'B', 'C', 'D']\n",
        "\n",
        "    plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
        "    plt.title(\"Pie Chart Example\")\n",
        "    plt.show()\n",
        "\n",
        "Adding Labels, Title, and Legend\n",
        "\n",
        "    x = [1, 2, 3]\n",
        "    y1 = [2, 4, 6]\n",
        "    y2 = [1, 3, 5]\n",
        "\n",
        "    plt.plot(x, y1, label=\"Line 1\")\n",
        "    plt.plot(x, y2, label=\"Line 2\")\n",
        "    plt.xlabel(\"X-axis\")\n",
        "    plt.ylabel(\"Y-axis\")\n",
        "    plt.title(\"Multiple Lines Example\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "Figure Size and Style\n",
        "\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.style.use('seaborn-v0_8')\n",
        "\n",
        "    x = [1, 2, 3, 4]\n",
        "    y = [10, 20, 25, 30]\n",
        "\n",
        "    plt.plot(x, y, marker='o')\n",
        "    plt.title(\"Styled Plot\")\n",
        "    plt.show()\n",
        "\n",
        "Subplots\n",
        "\n",
        "    x = [1, 2, 3, 4]\n",
        "    y1 = [1, 4, 9, 16]\n",
        "    y2 = [1, 2, 3, 4]\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, y1)\n",
        "    plt.title(\"Plot 1\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, y2)\n",
        "    plt.title(\"Plot 2\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "Saving Figures\n",
        "\n",
        "    plt.plot([1, 2, 3], [4, 5, 6])\n",
        "    plt.title(\"Save Example\")\n",
        "    plt.savefig(\"plot.png\", dpi=300)\n",
        "\n",
        "Common Utilities\n",
        "\n",
        "    plt.grid(True)          # Show gridlines\n",
        "    plt.xlim(0, 10)         # Set x-axis limits\n",
        "    plt.ylim(0, 20)         # Set y-axis limits\n",
        "    plt.axhline(5, color='r', linestyle='--')  # Horizontal line\n",
        "    plt.axvline(2, color='g', linestyle=':')   # Vertical line"
      ],
      "id": "1vXTvc-7KZUj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ii50eiLLKZUm"
      },
      "source": [
        "### Alternatives\n",
        "\n",
        "What I outlined are the commonly used libraries/methods in data science.\n",
        "Each have alternatives, each with proponents and opponents.\n",
        "\n",
        "For best reusability, stick to standards where it doesn’t matter, and if\n",
        "you do stray, pick the second or third most well known option, don’t\n",
        "force your reader to learn an obscure framework they’ll never see again."
      ],
      "id": "Ii50eiLLKZUm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odBcogMpKZUo"
      },
      "source": [
        "### Seaborn"
      ],
      "id": "odBcogMpKZUo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJqg8cOIKZUq"
      },
      "outputs": [],
      "source": [
        "# !pip install seaborn"
      ],
      "id": "KJqg8cOIKZUq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rZLBdcZKZUr"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns"
      ],
      "id": "9rZLBdcZKZUr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owS1mEogKZUt"
      },
      "outputs": [],
      "source": [
        "sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "sns.relplot(\n",
        "    data=df,\n",
        "    x=\"acceleration\",\n",
        "    y=\"sprintspeed\",\n",
        "    kind=\"scatter\",\n",
        "    alpha=0.05,\n",
        "    height=6,\n",
        "    aspect=1\n",
        ")"
      ],
      "id": "owS1mEogKZUt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlokWfFFKZUw"
      },
      "source": [
        "### Parquet\n",
        "\n",
        "Parquet is an alternative to pickle for storing data, but it’s designed\n",
        "specifically for tabular data. Many good built-in features like\n",
        "compression. Comes pre-installed with"
      ],
      "id": "xlokWfFFKZUw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMAXPMeFKZUy"
      },
      "outputs": [],
      "source": [
        "#!pip install pyarrow\n",
        "#install backend for pandas to use"
      ],
      "id": "FMAXPMeFKZUy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vji2U8WMKZU0"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('football_data/teamplayerlinks.csv')\n",
        "\n",
        "t = time.time()\n",
        "df.to_pickle(\"data.pkl\")\n",
        "pd.read_pickle(\"data.pkl\")\n",
        "print(\"pickle\", os.path.getsize(\"data.pkl\"))\n",
        "\n",
        "t = time.time()\n",
        "df.to_parquet(\"data.parquet\", engine=\"pyarrow\")\n",
        "pd.read_parquet(\"data.parquet\", engine=\"pyarrow\")\n",
        "print(\"parquet\", os.path.getsize(\"data.parquet\"))"
      ],
      "id": "vji2U8WMKZU0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7EwOb5cKZU3"
      },
      "source": [
        "Works across languages, enforces schema, columnar storage, partial\n",
        "reads.\n",
        "\n",
        "Caveat: only tabular data, and can be slower."
      ],
      "id": "Y7EwOb5cKZU3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqzk8LFNKZU6"
      },
      "outputs": [],
      "source": [
        "data = pd.DataFrame({\"a\": [1, 2, 'three']})\n",
        "\n",
        "data.to_pickle(\"data.pickle\")\n",
        "try:\n",
        "    data.to_parquet(\"data.parquet\")\n",
        "except Exception as e:\n",
        "    print(e)"
      ],
      "id": "iqzk8LFNKZU6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0ZvaU1iKZU9"
      },
      "outputs": [],
      "source": [
        "t = time.time()\n",
        "df.to_pickle(\"data.pkl\")\n",
        "pd.read_pickle(\"data.pkl\")\n",
        "print(\"pickle\", time.time() - t)\n",
        "\n",
        "t = time.time()\n",
        "df.to_parquet(\"data.parquet\", engine=\"pyarrow\")\n",
        "pd.read_parquet(\"data.parquet\", engine=\"pyarrow\")\n",
        "print(\"parquet\", time.time() - t)"
      ],
      "id": "P0ZvaU1iKZU9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPfLIyu8KZVB"
      },
      "source": [
        "### Polars\n",
        "\n",
        "An alternative to Pandas with a Rust backend. Faster on very big\n",
        "datasets, but not a big improvement on small ones. Slightly different\n",
        "syntax."
      ],
      "id": "lPfLIyu8KZVB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30guor3FKZVD"
      },
      "outputs": [],
      "source": [
        "# !pip install polars"
      ],
      "id": "30guor3FKZVD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwIe9oy6KZVH"
      },
      "outputs": [],
      "source": [
        "# import polars as pl\n",
        "\n",
        "# df_pd = pd.read_csv(\"football_data/players.csv\")\n",
        "# print(len(df_pd[df_pd[\"overallrating\"] > 90]))\n",
        "\n",
        "# df_pl = pl.read_csv(\"football_data/players.csv\")\n",
        "# print(len(df_pl.filter(pl.col(\"overallrating\") > 90)))"
      ],
      "id": "PwIe9oy6KZVH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQxQ8vTZKZVK"
      },
      "source": [
        "### Online Databases\n",
        "\n",
        "An example would be Amazon AWS Relational Database (RDS)"
      ],
      "id": "wQxQ8vTZKZVK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13lTLAKqKZVM"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd, sqlalchemy as sa\n",
        "\n",
        "# df = pd.read_csv(\"football_data/players.csv\")\n",
        "\n",
        "# DATABASE_URL = \"postgresql+psycopg2://USER:PASSWORD@HOST:5432/DBNAME\"\n",
        "# engine = sa.create_engine(DATABASE_URL)\n",
        "\n",
        "# with engine.begin() as conn:\n",
        "#     conn.exec_driver_sql(\"DROP TABLE IF EXISTS players\")\n",
        "#     df.to_sql(\"players\", conn, if_exists=\"replace\", index=False)\n",
        "#     for row in conn.exec_driver_sql(\"SELECT playerid FROM players WHERE potential > 92\"):\n",
        "#         print(row)"
      ],
      "id": "13lTLAKqKZVM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYJQvboRKZVP"
      },
      "source": [
        "### Online Storage\n",
        "\n",
        "For example Amazon AWS Simple Storage Service (S3)"
      ],
      "id": "IYJQvboRKZVP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgarj4xOKZVT"
      },
      "outputs": [],
      "source": [
        "# import boto3\n",
        "\n",
        "# bucket = \"your-bucket-name\"\n",
        "# key = \"players.csv\"\n",
        "# filename = \"players.csv\"\n",
        "\n",
        "# s3 = boto3.client(\"s3\")\n",
        "\n",
        "# # Upload file\n",
        "# s3.upload_file(filename, bucket, key)\n",
        "# print(\"Uploaded\", filename, \"to s3://\"+bucket+\"/\"+key)\n",
        "\n",
        "# # Download file\n",
        "# s3.download_file(bucket, key, \"players_downloaded.csv\")\n",
        "# print(\"Downloaded to players_downloaded.csv\")"
      ],
      "id": "zgarj4xOKZVT"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PATv_47DKZVW"
      },
      "source": [
        "### Exercises"
      ],
      "id": "PATv_47DKZVW"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0sdXzjGKZVY"
      },
      "source": [
        "### Exercise 1: Make a database"
      ],
      "id": "D0sdXzjGKZVY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_ElpgH3KZVb"
      },
      "source": [
        "### 1.1 Create a full SQL database from the following tables:\n",
        "\n",
        "-   players.csv\n",
        "-   teams.csv\n",
        "-   leagues.csv\n",
        "-   countries.csv\n",
        "-   teamplayerlinks.csv\n",
        "-   leagueteamlinks.csv\n",
        "-   models.csv"
      ],
      "id": "V_ElpgH3KZVb"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JX23HfuyKZVe"
      },
      "outputs": [],
      "source": [
        "# TODO\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "\n",
        "# Load CSVs\n",
        "countries = pd.read_csv('football_data/countries.csv')\n",
        "players = pd.read_csv('football_data/players.csv')\n",
        "teams = pd.read_csv('football_data/teams.csv')\n",
        "leagues = pd.read_csv('football_data/leagues.csv')\n",
        "tp_links = pd.read_csv('football_data/teamplayerlinks.csv')\n",
        "lt_links = pd.read_csv('football_data/leagueteamlinks.csv')\n",
        "models = pd.read_csv('football_data/models.csv')\n",
        "# Connect to SQLite (creates football.db)\n",
        "conn = sqlite3.connect(\"football.db\")\n",
        "\n",
        "# Save DataFrames into SQL tables\n",
        "countries.to_sql(\"countries\", conn, if_exists=\"replace\", index=False)\n",
        "players.to_sql(\"players\", conn, if_exists=\"replace\", index=False)\n",
        "teams.to_sql(\"teams\", conn, if_exists=\"replace\", index=False)\n",
        "leagues.to_sql(\"leagues\", conn, if_exists=\"replace\", index=False)\n",
        "tp_links.to_sql(\"teamplayerlinks\", conn, if_exists=\"replace\", index=False)\n",
        "lt_links.to_sql(\"leagueteamlinks\", conn, if_exists=\"replace\", index=False)\n",
        "models.to_sql(\"models\", conn, if_exists=\"replace\", index=False)\n",
        "\n",
        "conn.commit()"
      ],
      "id": "JX23HfuyKZVe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyA4_WTrKZVg"
      },
      "source": [
        "### 1.2 Make the appropriate indices:\n",
        "\n",
        "-   playerid\n",
        "-   teamid\n",
        "-   leagueid"
      ],
      "id": "eyA4_WTrKZVg"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN_NbbGkKZVk",
        "outputId": "79a4b836-84bd-4994-bb29-aac1ac9800af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Indices created successfully!\n"
          ]
        }
      ],
      "source": [
        "# Create indices for performance\n",
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect(\"football.db\")\n",
        "\n",
        "# Primary ID indices\n",
        "conn.execute(\"CREATE INDEX IF NOT EXISTS idx_playerid ON players(playerid)\")\n",
        "conn.execute(\"CREATE INDEX IF NOT EXISTS idx_teamid ON teams(teamid)\")\n",
        "conn.execute(\"CREATE INDEX IF NOT EXISTS idx_leagueid ON leagues(leagueid)\")\n",
        "\n",
        "# Foreign key indices for joins\n",
        "conn.execute(\"CREATE INDEX IF NOT EXISTS idx_models_playerid ON models(playerid)\")\n",
        "conn.execute(\"CREATE INDEX IF NOT EXISTS idx_teamplayerlinks_playerid ON teamplayerlinks(playerid)\")\n",
        "conn.execute(\"CREATE INDEX IF NOT EXISTS idx_teamplayerlinks_teamid ON teamplayerlinks(teamid)\")\n",
        "conn.execute(\"CREATE INDEX IF NOT EXISTS idx_leagueteamlinks_teamid ON leagueteamlinks(teamid)\")\n",
        "conn.execute(\"CREATE INDEX IF NOT EXISTS idx_leagueteamlinks_leagueid ON leagueteamlinks(leagueid)\")\n",
        "\n",
        "# Query-specific indices\n",
        "conn.execute(\"CREATE INDEX IF NOT EXISTS idx_leagues_leaguename ON leagues(leaguename)\")\n",
        "conn.execute(\"CREATE INDEX IF NOT EXISTS idx_players_penalties ON players(penalties)\")\n",
        "\n",
        "# Speed query indices\n",
        "conn.execute(\"CREATE INDEX IF NOT EXISTS idx_players_sprintspeed ON players(sprintspeed)\")\n",
        "conn.execute(\"CREATE INDEX IF NOT EXISTS idx_teams_teamname ON teams(teamname)\")\n",
        "\n",
        "conn.commit()\n",
        "conn.close()\n",
        "\n",
        "print(\"✅ Indices created successfully!\")"
      ],
      "id": "xN_NbbGkKZVk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAbZqbdGKZVm"
      },
      "source": [
        "### Exercise 2: Answer questions\n",
        "\n",
        "Use Pandas and SQL. Use the one that will be faster, neater, to solve\n",
        "the following questions.\n",
        "\n",
        "Make sure your code is correct and reasonably efficient. use SQL for at\n",
        "least one of them. Compare results and runtimes with other students."
      ],
      "id": "EAbZqbdGKZVm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKO7G991KZVp"
      },
      "source": [
        "### 2.1 Who are the best penalty takers in the `Premier League`?"
      ],
      "id": "xKO7G991KZVp"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0URJycHJKZVr",
        "outputId": "feb6333a-95b7-4453-a79d-06078faf7036"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   playerid       playername         teamname  penalties\n",
            "0    257534      Cole Palmer          Chelsea         90\n",
            "1    239085          Haaland  Manchester City         90\n",
            "2    212198  Bruno Fernandes          Man Utd         90\n",
            "3    204838     Raul Jimenez           Fulham         89\n",
            "4    205431  Niclas Fullkrug         West Ham         88\n",
            "5    246669      Bukayo Saka          Arsenal         87\n",
            "6    246669      Bukayo Saka             None         87\n",
            "7    246669      Bukayo Saka             None         87\n",
            "8    246669      Bukayo Saka             None         87\n",
            "9    246669      Bukayo Saka             None         87\n",
            "Optimized SQL runtime: 11.857324123382568 seconds\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import sqlite3\n",
        "import time\n",
        "\n",
        "conn = sqlite3.connect(\"football.db\")\n",
        "\n",
        "start = time.time()\n",
        "query = \"\"\"\n",
        "WITH premier_teams AS (\n",
        "    SELECT ltl.teamid\n",
        "    FROM leagueteamlinks ltl\n",
        "    JOIN leagues l ON l.leagueid = ltl.leagueid\n",
        "    WHERE l.leaguename = 'Premier League'\n",
        ")\n",
        "SELECT m.playerid,\n",
        "       m.playername,\n",
        "       t.teamname,\n",
        "       p.penalties\n",
        "FROM players p\n",
        "JOIN models m ON p.playerid = m.playerid\n",
        "JOIN teamplayerlinks tpl ON p.playerid = tpl.playerid\n",
        "JOIN premier_teams pt ON tpl.teamid = pt.teamid\n",
        "JOIN teams t ON tpl.teamid = t.teamid\n",
        "WHERE p.penalties IS NOT NULL\n",
        "ORDER BY p.penalties DESC\n",
        "LIMIT 10;\n",
        "\"\"\"\n",
        "best_penalty_sql = pd.read_sql_query(query, conn)\n",
        "print(best_penalty_sql)\n",
        "print(\"Optimized SQL runtime:\", time.time() - start, \"seconds\")\n",
        "\n",
        "conn.close()"
      ],
      "id": "0URJycHJKZVr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5tKjOPGKZVu"
      },
      "source": [
        "### 2.2 Which team has the biggest difference between the fastest and slowest player?"
      ],
      "id": "C5tKjOPGKZVu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cy6gD8NKZVw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import sqlite3\n",
        "import time\n",
        "\n",
        "conn = sqlite3.connect(\"football.db\")\n",
        "\n",
        "start = time.time()\n",
        "query = \"\"\"\n",
        "WITH team_speed_stats AS (\n",
        "    SELECT\n",
        "        t.teamname,\n",
        "        t.teamid,\n",
        "        MAX(p.sprintspeed) as fastest_player_speed,\n",
        "        MIN(p.sprintspeed) as slowest_player_speed,\n",
        "        MAX(p.sprintspeed) - MIN(p.sprintspeed) as speed_difference,\n",
        "        COUNT(p.playerid) as total_players\n",
        "    FROM teams t\n",
        "    JOIN teamplayerlinks tpl ON t.teamid = tpl.teamid\n",
        "    JOIN players p ON tpl.playerid = p.playerid\n",
        "    WHERE p.sprintspeed IS NOT NULL\n",
        "    GROUP BY t.teamid, t.teamname\n",
        "    HAVING COUNT(p.playerid) >= 5  -- Only teams with at least 5 players\n",
        ")\n",
        "SELECT\n",
        "    teamname,\n",
        "    speed_difference,\n",
        "    fastest_player_speed,\n",
        "    slowest_player_speed,\n",
        "    total_players\n",
        "FROM team_speed_stats\n",
        "ORDER BY speed_difference DESC\n",
        "LIMIT 10;\n",
        "\"\"\"\n",
        "\n",
        "speed_difference_results = pd.read_sql_query(query, conn)\n",
        "print(\"Teams with Biggest Speed Difference (Fastest vs Slowest Player):\")\n",
        "print(\"=\" * 70)\n",
        "print(speed_difference_results)\n",
        "print(f\"\\nQuery runtime: {time.time() - start:.4f} seconds\")\n",
        "\n",
        "conn.close()"
      ],
      "id": "9cy6gD8NKZVw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y92rZNS5KZVz"
      },
      "source": [
        "### 2.3 Which team has players of the most different nationalities?"
      ],
      "id": "Y92rZNS5KZVz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COaye8NaKZV1"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ],
      "id": "COaye8NaKZV1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNu-UjNwKZV6"
      },
      "source": [
        "### 2.4 Who is the player from `Kenya` who plays in `Poland`?"
      ],
      "id": "jNu-UjNwKZV6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSe9a6XbKZV8"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ],
      "id": "YSe9a6XbKZV8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVHWSvfOKZV-"
      },
      "source": [
        "### 2.5 Plot the relationship between age and average overall and potential ratings."
      ],
      "id": "QVHWSvfOKZV-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RQtxZuEKZWB"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ],
      "id": "0RQtxZuEKZWB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OL-N4wHKZWD"
      },
      "source": [
        "### 2.6 (extended) What is the most common tag (initials+number, like `CR7`, `LM10`) among the 1000 highest rated players?"
      ],
      "id": "1OL-N4wHKZWD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCtEddkOKZWI"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ],
      "id": "YCtEddkOKZWI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AORs_NN9KZWK"
      },
      "source": [
        "### 2.7 (extended) If in 5 years players who are now over 30 will retire, and others will reach half of their potential, which team will have the best starting 11?"
      ],
      "id": "AORs_NN9KZWK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0J3dYTvBKZWN"
      },
      "outputs": [],
      "source": [
        "# TODO"
      ],
      "id": "0J3dYTvBKZWN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9y7dD4vfKZWQ"
      },
      "source": [
        "### Exercise 3: Debug"
      ],
      "id": "9y7dD4vfKZWQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xifwtDtlKZWS"
      },
      "source": [
        "### 3.1 What are the best ratings for each team?\n",
        "\n",
        "We would like to query the above about a couple teams. But it’s taking\n",
        "us way too long."
      ],
      "id": "xifwtDtlKZWS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XkYLjAWKZWV"
      },
      "outputs": [],
      "source": [
        "teams = pd.read_csv('football_data/teams.csv')\n",
        "players = pd.read_csv('football_data/players.csv')\n",
        "tp_links = pd.read_csv('football_data/teamplayerlinks.csv')\n",
        "\n",
        "conn = sqlite3.connect(\"football31.db\")\n",
        "cur = conn.cursor()\n",
        "teams.to_sql(\"teams\", conn, if_exists=\"replace\", index=False)\n",
        "players.to_sql(\"players\", conn, if_exists=\"replace\", index=False)\n",
        "tp_links.to_sql(\"teamplayerlinks\", conn, if_exists=\"replace\", index=False)\n",
        "\n",
        "teams_list = teams['teamname'].unique()[1:104] #skip 1 bc that's the default value"
      ],
      "id": "-XkYLjAWKZWV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBCRISoZKZWY"
      },
      "outputs": [],
      "source": [
        "# todo\n",
        "# the query below should take about 0.1s"
      ],
      "id": "CBCRISoZKZWY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5IqAsZoCKZWa"
      },
      "outputs": [],
      "source": [
        "q = \"\"\"\n",
        "SELECT\n",
        "  t.teamid,\n",
        "  t.teamname,\n",
        "  MAX(p.overallrating) AS max_overallrating\n",
        "FROM teamplayerlinks AS l\n",
        "JOIN players AS p ON p.playerid = l.playerid\n",
        "JOIN teams   AS t ON t.teamid   = l.teamid\n",
        "WHERE t.teamid = (\n",
        "    SELECT MIN(teamid)\n",
        "    FROM teams\n",
        "    WHERE teamname = ?\n",
        ")\n",
        "GROUP BY t.teamid, t.teamname;\n",
        "\"\"\"\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "results = []\n",
        "for team in teams_list:\n",
        "    df_team = pd.read_sql_query(q, conn, params=[team])\n",
        "    results.append(df_team)\n",
        "\n",
        "df = pd.concat(results, ignore_index=True)\n",
        "\n",
        "print(time.time() - start)\n",
        "print(df)"
      ],
      "id": "5IqAsZoCKZWa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3jYw8sDKZWd"
      },
      "outputs": [],
      "source": [
        "conn.close()"
      ],
      "id": "C3jYw8sDKZWd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cp8xHIUIKZWf"
      },
      "source": [
        "### 3.2 Which period of 365 days had the most footballers born?\n",
        "\n",
        "Improve on the code below. It should be able to run in a fraction of a\n",
        "second. *hint: cumulative sum*"
      ],
      "id": "cp8xHIUIKZWf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-y07P-pTKZWh"
      },
      "outputs": [],
      "source": [
        "players = pd.read_csv('football_data/players.csv')\n",
        "start = time.time()\n",
        "players = players[players['birthdate']>0]\n",
        "counts = []\n",
        "for i in range(min(players['birthdate']), max(players['birthdate'])-365):\n",
        "    bigger = players['birthdate'] >= i\n",
        "    smaller = players['birthdate'] < i+365\n",
        "    counts.append(len(players[bigger*smaller]))\n",
        "print(np.argmax(counts)+min(players['birthdate']))\n",
        "print(time.time()-start)"
      ],
      "id": "-y07P-pTKZWh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RRW2a-QKZWk"
      },
      "source": [
        "### 3.3 Average height in metres by nationality\n",
        "\n",
        "The below code is supposed to calculate the average height of players\n",
        "from different countries. It has a subtle logical bug that makes all the\n",
        "returned heights tiny - find and describe it."
      ],
      "id": "0RRW2a-QKZWk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8_y1cmuKZWn"
      },
      "outputs": [],
      "source": [
        "players = pd.read_csv('football_data/players.csv')\n",
        "countries = pd.read_csv('football_data/countries.csv')\n",
        "players = players[players['playerid']>0]\n",
        "nationalities = players['nationality'].unique()\n",
        "mean_heights_m = {}\n",
        "for nationality in nationalities:\n",
        "    players_temp = players\n",
        "    players_temp['height'] = players_temp['height']/100\n",
        "    mean_value = players_temp[players_temp['nationality'] == nationality]['height'].mean()\n",
        "    mean_heights_m[nationality] = mean_value\n",
        "countries['height'] = countries['countryid'].map(mean_heights_m)\n",
        "countries"
      ],
      "id": "d8_y1cmuKZWn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLhklMnYKZWq"
      },
      "outputs": [],
      "source": [
        "#TODO describe the bug, and the minimal fix"
      ],
      "id": "tLhklMnYKZWq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Q5yNrM1KZWt"
      },
      "source": [
        "Other than the minimal fix, the code is in general overcomplicated. Now,\n",
        "rewrite the code - it can probably be much faster and half the lines.\n",
        "*hint: use groupby*"
      ],
      "id": "4Q5yNrM1KZWt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyzI1YGgKZWv"
      },
      "outputs": [],
      "source": [
        "#TODO"
      ],
      "id": "NyzI1YGgKZWv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt-kMtvKKZWx"
      },
      "source": [
        "### 3.4 Nested select\n",
        "\n",
        "We will be looking for the numbers of players from each country wearing\n",
        "numbers `1-11`.\n",
        "\n",
        "The below code joins the two dataframes, and then selects based on the\n",
        "criteria. Change it slightly, so it can run about 10 times faster."
      ],
      "id": "Bt-kMtvKKZWx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqFRfntWKZWz"
      },
      "outputs": [],
      "source": [
        "countries = pd.read_csv('football_data/countries.csv')\n",
        "players = pd.read_csv('football_data/players.csv')\n",
        "players = players[players['playerid']>1]\n",
        "tp_links = pd.read_csv('football_data/teamplayerlinks.csv')\n",
        "tp_links = tp_links[tp_links['playerid']>1]\n",
        "\n",
        "start = time.time()\n",
        "counts = {}\n",
        "for i, (countryid, countryname) in countries.iterrows(): # this is inefficient but leave it, look for improvements within the loop - also don't move anything out of the loop\n",
        "    joined_df = players.merge(tp_links, on='playerid', how='inner')\n",
        "    joined_df = joined_df[(joined_df['nationality']==countryid)&(joined_df['jerseynumber']<=11)]\n",
        "    counts[countryname] = len(joined_df)\n",
        "print(time.time() - start)\n",
        "counts['Kenya']"
      ],
      "id": "NqFRfntWKZWz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DheQvlWGKZW3"
      },
      "source": [
        "If we try to recreate the same speed improvement by reordering the\n",
        "equivalent SQL query:\n",
        "\n",
        "    SELECT COUNT(*) AS cnt\n",
        "    FROM players AS p\n",
        "    JOIN teamplayerlinks AS l\n",
        "        ON p.playerid = l.playerid\n",
        "    WHERE p.playerid > 1\n",
        "      AND l.playerid > 1\n",
        "      AND p.nationality = ?\n",
        "      AND l.jerseynumber <= 11;\n",
        "\n",
        "For example into something like this:\n",
        "\n",
        "    SELECT COUNT(*) AS cnt\n",
        "    FROM (\n",
        "        SELECT playerid\n",
        "        FROM players\n",
        "        WHERE playerid > 1\n",
        "          AND nationality = ?\n",
        "    ) AS p\n",
        "    JOIN (\n",
        "        SELECT playerid\n",
        "        FROM teamplayerlinks\n",
        "        WHERE playerid > 1\n",
        "          AND jerseynumber <= 11\n",
        "    ) AS l\n",
        "    ON p.playerid = l.playerid;\n",
        "\n",
        "We don’t actually see any improvement. This is because SQLite does this\n",
        "optimisation for us under the hood!\n",
        "\n",
        "End of Practical 1¾\n",
        "\n",
        "     _______  __   __  _______  __    _  ___   _  _______  __\n",
        "    |       ||  | |  ||   _   ||  |  | ||   | | ||       ||  |\n",
        "    |_     _||  |_|  ||  |_|  ||   |_| ||   |_| ||  _____||  |\n",
        "      |   |  |       ||       ||       ||      _|| |_____ |  |\n",
        "      |   |  |       ||       ||  _    ||     |_ |_____  ||__|\n",
        "      |   |  |   _   ||   _   || | |   ||    _  | _____| | __\n",
        "      |___|  |__| |__||__| |__||_|  |__||___| |_||_______||__|\n",
        "\n",
        "::: {.cell .markdown}\n",
        "\n",
        "## Thanks!\n",
        "\n",
        "For more information on these subjects and more you might want to check\n",
        "the following resources.\n",
        "\n",
        "-   book: [The Atomic\n",
        "    Human](https://www.penguin.co.uk/books/455130/the-atomic-human-by-lawrence-neil-d/9780241625248)\n",
        "-   twitter: [@lawrennd](https://twitter.com/lawrennd)\n",
        "-   podcast: [The Talking Machines](http://thetalkingmachines.com)\n",
        "-   newspaper: [Guardian Profile\n",
        "    Page](http://www.theguardian.com/profile/neil-lawrence)\n",
        "-   blog:\n",
        "    [http://inverseprobability.com](http://inverseprobability.com/blog.html)"
      ],
      "id": "DheQvlWGKZW3"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  }
}